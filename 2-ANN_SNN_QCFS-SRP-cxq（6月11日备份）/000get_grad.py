#!/usr/bin/env python3

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import argparse
import os
from Models import modelpool
from Preprocess import datapool
from utils import seed_all
from Models.layer import IF

# å¯¼å…¥000snngrad.pyä¸­çš„SNNGradientAnalyzer
try:
    import importlib.util
    spec = importlib.util.spec_from_file_location("snngrad", "000snngrad.py")
    snngrad_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(snngrad_module)
    SNNGradientAnalyzer = snngrad_module.SNNGradientAnalyzer
except Exception as e:
    print(f"æ— æ³•å¯¼å…¥000snngrad.py: {e}")
    SNNGradientAnalyzer = None

class SNNSurrogateGradient:
    """SNNæ¨¡æ‹Ÿæ¢¯åº¦å¤„ç†å™¨ï¼Œä¸“é—¨ç”¨äºIFå±‚æ¢¯åº¦è®¡ç®—"""
    
    def __init__(self, model, temperature=5.0):
        self.model = model
        self.temperature = temperature
        self.if_activations = {}
        self.handles = []
        
    def register_if_hooks(self):
        """ä¸ºIFå±‚æ³¨å†Œå‰å‘é’©å­ä»¥æ•è·æ¿€æ´»å€¼"""
        self.remove_hooks()
        
        for name, module in self.model.named_modules():
            if isinstance(module, IF):
                hook = self.make_if_forward_hook(name)
                handle = module.register_forward_hook(hook)
                self.handles.append(handle)
                
        print(f"å·²ä¸º {len(self.handles)} ä¸ªIFå±‚æ³¨å†Œé’©å­")
    
    def make_if_forward_hook(self, layer_name):
        """åˆ›å»ºIFå±‚å‰å‘é’©å­"""
        def forward_hook(module, input, output):
            if len(input) > 0 and input[0] is not None:
                # å­˜å‚¨è¾“å…¥æ¿€æ´»å€¼ï¼ˆè†œç”µä½ï¼‰
                self.if_activations[layer_name] = input[0].detach().clone()
        return forward_hook
    
    def apply_surrogate_gradient_to_if_layers(self):
        """ä¸ºIFå±‚æ‰‹åŠ¨åº”ç”¨æ¨¡æ‹Ÿæ¢¯åº¦"""
        applied_count = 0
        
        for name, module in self.model.named_modules():
            if isinstance(module, IF) and module.thresh.grad is not None:
                # è·å–å¯¹åº”çš„æ¿€æ´»å€¼
                if name in self.if_activations:
                    activation = self.if_activations[name]
                    
                    # è®¡ç®—æ¨¡æ‹Ÿæ¢¯åº¦
                    surrogate_grad = self.sigmoid_surrogate_grad(activation - module.thresh)
                    
                    # è®¡ç®—æ¿€æ´»å€¼ç›¸å¯¹äºé˜ˆå€¼çš„å½±å“
                    activation_effect = surrogate_grad.mean().item()
                    
                    # ä¿®æ­£é˜ˆå€¼æ¢¯åº¦
                    original_grad = module.thresh.grad.item()
                    modified_grad = original_grad * activation_effect
                    
                    # åº”ç”¨ä¿®æ­£åçš„æ¢¯åº¦
                    module.thresh.grad.data.fill_(modified_grad)
                    
                    applied_count += 1
                    print(f"IFå±‚ {name}: åŸæ¢¯åº¦={original_grad:.6f}, ä¿®æ­£æ¢¯åº¦={modified_grad:.6f}, æ¿€æ´»æ•ˆåº”={activation_effect:.6f}")
        
        return applied_count
    
    def sigmoid_surrogate_grad(self, x):
        """Sigmoidæ¨¡æ‹Ÿæ¢¯åº¦å‡½æ•°"""
        return torch.sigmoid(self.temperature * x) * (1 - torch.sigmoid(self.temperature * x))
    
    def triangular_surrogate_grad(self, x):
        """ä¸‰è§’å½¢æ¨¡æ‹Ÿæ¢¯åº¦å‡½æ•°"""
        return torch.clamp(1.0 - torch.abs(x), 0.0, 1.0)
    
    def remove_hooks(self):
        """ç§»é™¤æ‰€æœ‰é’©å­"""
        for handle in self.handles:
            handle.remove()
        self.handles = []

def get_params_grad(model):
    """
    è·å–æ¨¡å‹å‚æ•°å’Œå¯¹åº”çš„æ¢¯åº¦
    å‚è€ƒè‡ªhessian_weight_importance.py
    """
    params = []
    grads = []
    for param in model.parameters():
        if not param.requires_grad:
            continue
        params.append(param)
        grads.append(0. if param.grad is None else param.grad + 0.)
    return params, grads

def print_params_and_gradients(model):
    """æ‰“å°æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("VGG16æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯")
    print("="*80)
    
    params, grads = get_params_grad(model)
    
    print(f"æ€»å…±æœ‰ {len(params)} ä¸ªéœ€è¦æ¢¯åº¦çš„å‚æ•°")
    print("-"*80)
    
    total_params = 0
    total_grad_norm = 0.0
    
    for i, (param, grad) in enumerate(zip(params, grads)):
        param_count = param.numel()
        total_params += param_count
        
        # æ¢¯åº¦ç»Ÿè®¡
        if torch.is_tensor(grad):
            grad_norm = grad.norm().item()
            grad_mean = grad.mean().item()
            grad_std = grad.std().item()
            non_zero_elements = (grad != 0).sum().item()
            total_grad_norm += grad_norm ** 2
        else:
            grad_norm = grad_mean = grad_std = 0.0
            non_zero_elements = 0
        
        print(f"å‚æ•° {i+1:2d}: å½¢çŠ¶={list(param.shape)}, æ•°é‡={param_count:,}")
        print(f"  å‚æ•°ç»Ÿè®¡: å‡å€¼={param.mean().item():.6f}, æ ‡å‡†å·®={param.std().item():.6f}")
        print(f"  æ¢¯åº¦ç»Ÿè®¡: èŒƒæ•°={grad_norm:.6f}, å‡å€¼={grad_mean:.6f}, æ ‡å‡†å·®={grad_std:.6f}")
        print(f"  éé›¶æ¢¯åº¦: {non_zero_elements:,}/{param_count:,} ({100*non_zero_elements/param_count:.2f}%)")
        print("-"*40)
    
    total_grad_norm = np.sqrt(total_grad_norm)
    print(f"\næ€»ç»“: {total_params:,} ä¸ªå‚æ•°, æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")
    print("="*80)

def print_if_layers_only(model):
    """åªæ‰“å°IFå±‚çš„å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("IFå±‚é˜ˆå€¼å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯")
    print("="*80)
    
    if_layer_count = 0
    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue
        
        # åªæ˜¾ç¤ºIFå±‚çš„é˜ˆå€¼å‚æ•°
        if 'thresh' in name.lower() and param.numel() == 1:
            if_layer_count += 1
            print(f"IFå±‚é˜ˆå€¼: {name}")
            print(f"  å½¢çŠ¶: {list(param.shape)}, å‚æ•°æ•°é‡: {param.numel():,}")
            print(f"  é˜ˆå€¼: {param.data.item():.6f}")
            
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_mean = param.grad.mean().item()
                grad_value = param.grad.data.item()
                print(f"  æ¢¯åº¦å€¼: {grad_value:.6f}")
                print(f"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}, æ¢¯åº¦å‡å€¼: {grad_mean:.6f}")
            else:
                print(f"  æ¢¯åº¦: None")
            print("-"*60)
    
    if if_layer_count == 0:
        print("æœªæ‰¾åˆ°IFå±‚é˜ˆå€¼å‚æ•°")
    else:
        print(f"æ€»å…±æ‰¾åˆ° {if_layer_count} ä¸ªIFå±‚é˜ˆå€¼å‚æ•°")
    print("="*80)

def print_all_if_module_info(model):
    """æ‰“å°æ‰€æœ‰IFæ¨¡å—çš„è¯¦ç»†ä¿¡æ¯"""
    print("="*80)
    print("IFæ¨¡å—è¯¦ç»†ä¿¡æ¯")
    print("="*80)
    
    from Models.layer import IF
    
    if_module_count = 0
    for name, module in model.named_modules():
        if isinstance(module, IF):
            if_module_count += 1
            print(f"IFæ¨¡å—: {name}")
            print(f"  é˜ˆå€¼(thresh): {module.thresh.item():.6f}")
            print(f"  gammaå‚æ•°: {module.gama}")
            print(f"  æ—¶é—´æ­¥æ•°(T): {module.T}")
            print(f"  é‡åŒ–çº§åˆ«(L): {module.L}")
            
            # æ‰“å°é˜ˆå€¼å‚æ•°çš„æ¢¯åº¦
            if module.thresh.grad is not None:
                thresh_grad = module.thresh.grad.item()
                print(f"  é˜ˆå€¼æ¢¯åº¦: {thresh_grad:.6f}")
            else:
                print(f"  é˜ˆå€¼æ¢¯åº¦: None")
            
            print("-"*60)
    
    if if_module_count == 0:
        print("æœªæ‰¾åˆ°IFæ¨¡å—")
    else:
        print(f"æ€»å…±æ‰¾åˆ° {if_module_count} ä¸ªIFæ¨¡å—")
    print("="*80)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è·å–VGG16å‚æ•°å’Œæ¢¯åº¦')
    parser.add_argument('--batch_size', default=32, type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', default='0', type=str, help='è®¾å¤‡')
    parser.add_argument('--seed', default=42, type=int, help='éšæœºç§å­')
    parser.add_argument('--mode', choices=['ann', 'snn'], default='snn', help='æ¨¡å¼')

    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒ
    os.environ["CUDA_VISIBLE_DEVICES"] = args.device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    seed_all(args.seed)
    
    print(f"è®¾å¤‡: {device}, éšæœºç§å­: {args.seed}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºVGG16æ¨¡å‹...")
        model = modelpool('vgg16', 'cifar10')
        
        # ç›´æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = '/root/autodl-tmp/0-ANN2SNN-Allinone/2-ANN_SNN_QCFS-SRP/cifar10-checkpoints/vgg16_wd[0.0005].pth'
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # å¤„ç†æ—§ç‰ˆæœ¬state_dictçš„å…¼å®¹æ€§
        keys = list(state_dict.keys())
        for k in keys:
            if "relu.up" in k:
                state_dict[k[:-7]+'act.thresh'] = state_dict.pop(k)
            elif "up" in k:
                state_dict[k[:-2]+'thresh'] = state_dict.pop(k)
        
        model.load_state_dict(state_dict)
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        if args.mode == 'snn':
            model.set_T(8)
            model.set_L(4)
            print("è®¾ç½®ä¸ºSNNæ¨¡å¼")
        else:
            model.set_T(0)
            print("è®¾ç½®ä¸ºANNæ¨¡å¼")
        
        model.to(device)
        model.train()
        
        # åŠ è½½æ•°æ®
        print("åŠ è½½CIFAR10æ•°æ®é›†...")
        train_loader, test_loader = datapool('cifar10', args.batch_size)
        
        # è·å–ä¸€æ‰¹æ•°æ®
        data_iter = iter(train_loader)
        images, labels = next(data_iter)
        images, labels = images.to(device), labels.to(device)
        
        print(f"è¾“å…¥å½¢çŠ¶: {images.shape}, æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        
        # å‰å‘ä¼ æ’­
        print("æ‰§è¡Œå‰å‘ä¼ æ’­...")
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01)
        
        optimizer.zero_grad()
        
        try:
            outputs = model(images)
            
            # å¤„ç†SNNè¾“å‡º
            if len(outputs.shape) > 2:
                outputs = outputs.mean(0)
            
            loss = criterion(outputs, labels)
            print(f"æŸå¤±: {loss.item():.6f}")
        except Exception as e:
            print(f"å‰å‘ä¼ æ’­å‡ºé”™: {e}")
            if args.mode == 'snn':
                print("SNNæ¨¡å¼å¯èƒ½å­˜åœ¨æ—¶é—´ç»´åº¦é—®é¢˜ï¼Œå°è¯•é™çº§åˆ°T=1")
                model.set_T(1)
                outputs = model(images)
                if len(outputs.shape) > 2:
                    outputs = outputs.mean(0)
                loss = criterion(outputs, labels)
                print(f"T=1æ¨¡å¼æŸå¤±: {loss.item():.6f}")
            else:
                raise e
        
        # åå‘ä¼ æ’­
        print("æ‰§è¡Œåå‘ä¼ æ’­...")
        
        if args.mode == 'snn':
            # SNNæ¨¡å¼ï¼šä½¿ç”¨000snngrad.pyä¸­çš„æ¨¡æ‹Ÿæ¢¯åº¦
            print("SNNæ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ¢¯åº¦åå‘ä¼ æ’­")
            
            if SNNGradientAnalyzer is not None:
                # åˆ›å»ºSNNæ¢¯åº¦åˆ†æå™¨
                snn_analyzer = SNNGradientAnalyzer(model, surrogate_grad_type='sigmoid', grad_scale=5.0)
                
                # ä½¿ç”¨æ¨¡æ‹Ÿæ¢¯åº¦è¿›è¡Œåå‘ä¼ æ’­
                print("ä½¿ç”¨æ¨¡æ‹Ÿæ¢¯åº¦è¿›è¡Œåå‘ä¼ æ’­...")
                try:
                    # ä½¿ç”¨backward_with_surrogateæ–¹æ³•
                    loss = snn_analyzer.backward_with_surrogate(outputs, labels, criterion)
                    print(f"âœ… æ¨¡æ‹Ÿæ¢¯åº¦åå‘ä¼ æ’­å®Œæˆï¼ŒæŸå¤±: {loss.item():.6f}")
                except Exception as e:
                    print(f"æ¨¡æ‹Ÿæ¢¯åº¦åå‘ä¼ æ’­å‡ºé”™: {e}")
                    print("å›é€€åˆ°æ ‡å‡†åå‘ä¼ æ’­")
                    model.zero_grad()  # æ¸…ç©ºæ¢¯åº¦é¿å…é‡å¤åå‘ä¼ æ’­
                    loss.backward(retain_graph=True)
                
                # æ¸…ç†é’©å­
                if hasattr(snn_analyzer, 'gradient_hooks'):
                    for handle in snn_analyzer.gradient_hooks.values():
                        handle.remove()
                        
                print("âœ… å®ŒæˆSNNæ¨¡æ‹Ÿæ¢¯åº¦å¤„ç†")
            else:
                print("âš ï¸ æ— æ³•å¯¼å…¥SNNGradientAnalyzerï¼Œä½¿ç”¨æ ‡å‡†åå‘ä¼ æ’­")
                loss.backward()
        else:
            # ANNæ¨¡å¼ï¼šæ ‡å‡†åå‘ä¼ æ’­
            loss.backward()
        
        # åªæ‰“å°IFå±‚ä¿¡æ¯
        print_if_layers_only(model)
        print_all_if_module_info(model)
        
        print("âœ… å®Œæˆ!")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("python 000get_grad.py --mode snn  # SNNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯")
        print("python 000get_grad.py --mode ann  # ANNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 