#!/usr/bin/env python3


import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import argparse
import os
import sys
from datetime import datetime
from Models import modelpool
from Preprocess import datapool
from utils import seed_all
import pandas as pd

def get_params_grad(model):
    """
    è·å–æ¨¡å‹å‚æ•°å’Œå¯¹åº”çš„æ¢¯åº¦
    å‚è€ƒè‡ªhessian_weight_importance.py
    """
    params = []
    grads = []
    for param in model.parameters():
        if not param.requires_grad:
            continue
        params.append(param)
        grads.append(0. if param.grad is None else param.grad + 0.)
    return params, grads

def print_params_and_gradients(model):
    """æ‰“å°æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("VGG16æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯")
    print("="*80)
    
    params, grads = get_params_grad(model)
    
    print(f"æ€»å…±æœ‰ {len(params)} ä¸ªéœ€è¦æ¢¯åº¦çš„å‚æ•°")
    print("-"*80)
    
    total_params = 0
    total_grad_norm = 0.0
    
    for i, (param, grad) in enumerate(zip(params, grads)):
        param_count = param.numel()
        total_params += param_count
        
        # æ¢¯åº¦ç»Ÿè®¡
        if torch.is_tensor(grad):
            grad_norm = grad.norm().item()
            grad_mean = grad.mean().item()
            grad_std = grad.std().item()
            non_zero_elements = (grad != 0).sum().item()
            total_grad_norm += grad_norm ** 2
        else:
            grad_norm = grad_mean = grad_std = 0.0
            non_zero_elements = 0
        
        print(f"å‚æ•° {i+1:2d}: å½¢çŠ¶={list(param.shape)}, æ•°é‡={param_count:,}")
        print(f"  å‚æ•°ç»Ÿè®¡: å‡å€¼={param.mean().item():.6f}, æ ‡å‡†å·®={param.std().item():.6f}")
        print(f"  æ¢¯åº¦ç»Ÿè®¡: èŒƒæ•°={grad_norm:.6f}, å‡å€¼={grad_mean:.6f}, æ ‡å‡†å·®={grad_std:.6f}")
        print(f"  éé›¶æ¢¯åº¦: {non_zero_elements:,}/{param_count:,} ({100*non_zero_elements/param_count:.2f}%)")
        print("-"*40)
    
    total_grad_norm = np.sqrt(total_grad_norm)
    print(f"\næ€»ç»“: {total_params:,} ä¸ªå‚æ•°, æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")
    print("="*80)

def print_if_layers_only(model):
    """åªæ‰“å°IFå±‚çš„å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("IFå±‚é˜ˆå€¼å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯")
    print("="*80)
    
    if_layer_count = 0
    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue
        
        # åªæ˜¾ç¤ºIFå±‚çš„é˜ˆå€¼å‚æ•°
        if 'thresh' in name.lower() and param.numel() == 1:
            if_layer_count += 1
            print(f"IFå±‚é˜ˆå€¼: {name}")
            print(f"  å½¢çŠ¶: {list(param.shape)}, å‚æ•°æ•°é‡: {param.numel():,}")
            print(f"  é˜ˆå€¼: {param.data.item():.6f}")
            
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_mean = param.grad.mean().item()
                grad_value = param.grad.data.item()
                print(f"  æ¢¯åº¦å€¼: {grad_value:.6f}")
                print(f"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}, æ¢¯åº¦å‡å€¼: {grad_mean:.6f}")
            else:
                print(f"  æ¢¯åº¦: None")
            print("-"*60)
    
    if if_layer_count == 0:
        print("æœªæ‰¾åˆ°IFå±‚é˜ˆå€¼å‚æ•°")
    else:
        print(f"æ€»å…±æ‰¾åˆ° {if_layer_count} ä¸ªIFå±‚é˜ˆå€¼å‚æ•°")
    print("="*80)

def print_all_if_module_info(model):
    """æ‰“å°æ‰€æœ‰IFæ¨¡å—çš„è¯¦ç»†ä¿¡æ¯"""
    print("="*80)
    print("IFæ¨¡å—è¯¦ç»†ä¿¡æ¯")
    print("="*80)
    
    from Models.layer import IF
    
    if_module_count = 0
    for name, module in model.named_modules():
        if isinstance(module, IF):
            if_module_count += 1
            print(f"IFæ¨¡å—: {name}")
            print(f"  é˜ˆå€¼(thresh): {module.thresh.item():.6f}")
            print(f"  gammaå‚æ•°: {module.gama}")
            print(f"  æ—¶é—´æ­¥æ•°(T): {module.T}")
            print(f"  é‡åŒ–çº§åˆ«(L): {module.L}")
            
            # æ‰“å°é˜ˆå€¼å‚æ•°çš„æ¢¯åº¦
            if module.thresh.grad is not None:
                thresh_grad = module.thresh.grad.item()
                print(f"  é˜ˆå€¼æ¢¯åº¦: {thresh_grad:.6f}")
            else:
                print(f"  é˜ˆå€¼æ¢¯åº¦: None")
            
            print("-"*60)
    
    if if_module_count == 0:
        print("æœªæ‰¾åˆ°IFæ¨¡å—")
    else:
        print(f"æ€»å…±æ‰¾åˆ° {if_module_count} ä¸ªIFæ¨¡å—")
    print("="*80)

class GradientAnalyzer:
    """å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†æå™¨ï¼ˆå‚è€ƒgradient_cray.pyï¼‰"""
    def __init__(self, model):
        self.model = model
        self.gradient_hooks = {}
        self.gradient_records = {}
        
    def register_gradient_hooks(self):
        """ä¸ºæ‰€æœ‰å…¨è¿æ¥å±‚æ³¨å†Œæ¢¯åº¦è®°å½•é’©å­"""
        print("æ³¨å†Œå…¨è¿æ¥å±‚æ¢¯åº¦é’©å­...")
        
        # ç§»é™¤ç°æœ‰é’©å­
        for handle in self.gradient_hooks.values():
            handle.remove()
        self.gradient_hooks = {}
        self.gradient_records = {}
        
        # æŸ¥æ‰¾æ‰€æœ‰å…¨è¿æ¥å±‚
        fc_count = 0
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Linear):
                fc_count += 1
                # ä¸ºæƒé‡å‚æ•°æ³¨å†Œæ¢¯åº¦é’©å­
                hook = self._gradient_hook(name)
                handle = module.weight.register_hook(hook)
                self.gradient_hooks[name] = handle
                print(f"  - æ³¨å†Œé’©å­: {name} (è¾“å…¥={module.in_features}, è¾“å‡º={module.out_features})")
        
        print(f"æ€»å…±æ³¨å†Œäº† {fc_count} ä¸ªå…¨è¿æ¥å±‚çš„æ¢¯åº¦é’©å­")
        
    def _gradient_hook(self, name):
        """åˆ›å»ºæ¢¯åº¦é’©å­å‡½æ•°"""
        def hook(grad):
            # ç¡®ä¿æ¢¯åº¦æœ‰æ•ˆ
            if grad is None:
                return
            
            # è®¡ç®—æ¯ä¸ªè¾“å‡ºç¥ç»å…ƒçš„å¹³å‡æ¢¯åº¦
            if grad.dim() > 1:
                # å…¨è¿æ¥å±‚: å¯¹è¾“å…¥ç»´åº¦æ±‚å¹³å‡
                neuron_grads = grad.abs().mean(dim=1)  # [out_features]
            else:
                # 1Dæƒ…å†µ
                neuron_grads = grad.abs()
            
            # ä¿å­˜æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
            self.gradient_records[name] = neuron_grads.detach().cpu()
        return hook
    
    def analyze_gradients(self, dataloader, criterion, num_batches=5):
        """
        åˆ†æå…¨è¿æ¥å±‚æ¢¯åº¦åˆ†å¸ƒï¼ˆå‚è€ƒgradient_cray.pyï¼‰
        
        å‚æ•°:
        dataloader - æ•°æ®åŠ è½½å™¨
        criterion - æŸå¤±å‡½æ•°
        num_batches - åˆ†ææ‰¹æ¬¡æ•°
        
        è¿”å›:
        gradient_stats - æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
        """
        print(f"\nå¼€å§‹åˆ†æ {num_batches} ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦åˆ†å¸ƒ...")
        
        # æ³¨å†Œæ¢¯åº¦é’©å­
        self.register_gradient_hooks()
        
        # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # æ¢¯åº¦ç»Ÿè®¡æ”¶é›†å™¨
        gradient_stats = {}
        for name in self.gradient_hooks.keys():
            gradient_stats[name] = {'values': []}
        
        # å¤„ç†æŒ‡å®šæ‰¹æ¬¡æ•°æ®
        batch_count = 0
        data_iter = iter(dataloader)
        
        for batch_idx in range(num_batches):
            try:
                inputs, targets = next(data_iter)
                inputs, targets = inputs.to(next(self.model.parameters()).device), targets.to(next(self.model.parameters()).device)
            except StopIteration:
                print(f"æ•°æ®ä¸è¶³ï¼Œåªå¤„ç†äº† {batch_idx} ä¸ªæ‰¹æ¬¡")
                break
                
            # æ¸…ç©ºæ¢¯åº¦
            self.model.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(inputs)
            
            # å¤„ç†SNNè¾“å‡º
            if len(outputs.shape) > 2:
                outputs = outputs.mean(0)  # å¯¹æ—¶é—´ç»´åº¦æ±‚å¹³å‡
            
            # è®¡ç®—æŸå¤±
            loss = criterion(outputs, targets)
            
            # åå‘ä¼ æ’­ï¼ˆè§¦å‘æ¢¯åº¦é’©å­ï¼‰
            loss.backward()
            
            # æ”¶é›†æ¢¯åº¦æ•°æ®
            for name, grads in self.gradient_records.items():
                if grads is not None:
                    gradient_stats[name]['values'].extend(grads.numpy())
            
            batch_count += 1
            print(f"  å¤„ç†æ‰¹æ¬¡ {batch_count}/{num_batches}, æŸå¤±: {loss.item():.6f}")
        
        # è®¡ç®—æ¢¯åº¦ç»Ÿè®¡
        print("\nè®¡ç®—æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯...")
        for name, stats in gradient_stats.items():
            if stats['values']:
                values = np.array(stats['values'])
                stats['mean'] = np.mean(values)
                stats['std'] = np.std(values)
                stats['min'] = np.min(values)
                stats['max'] = np.max(values)
                stats['median'] = np.median(values)
                stats['num_neurons'] = len(values)
                
                # è®¡ç®—ç™¾åˆ†ä½æ•°
                stats['p25'] = np.percentile(values, 25)
                stats['p75'] = np.percentile(values, 75)
                stats['p95'] = np.percentile(values, 95)
        
        return gradient_stats
    
    def get_low_gradient_neurons(self, gradient_stats, ratio=0.1):
        """
        è¯†åˆ«ä½æ¢¯åº¦ç¥ç»å…ƒ
        
        å‚æ•°:
        gradient_stats - analyze_gradientsè¿”å›çš„ç»Ÿè®¡æ•°æ®
        ratio - è¦è¯†åˆ«çš„ç¥ç»å…ƒæ¯”ä¾‹
        
        è¿”å›:
        low_gradient_neurons - ä½æ¢¯åº¦ç¥ç»å…ƒåˆ—è¡¨
        """
        low_neurons = []
        
        # å¤„ç†æ¯å±‚çš„æ¢¯åº¦ç»Ÿè®¡
        for layer_name, stats in gradient_stats.items():
            if 'values' not in stats or not stats['values']:
                continue
                
            # å¯¹æ¢¯åº¦å€¼æ’åº
            grads = np.array(stats['values'])
            sorted_indices = np.argsort(grads)
            
            # è®¡ç®—ä½æ¢¯åº¦é˜ˆå€¼
            num_low = int(len(grads) * ratio)
            
            # æ”¶é›†ä½æ¢¯åº¦ç¥ç»å…ƒ
            for idx in sorted_indices[:num_low]:
                low_neurons.append({
                    'layer': layer_name,
                    'neuron_index': idx,
                    'grad_value': grads[idx],
                    'grad_percentile': (np.searchsorted(np.sort(grads), grads[idx]) + 1) / len(grads)
                })
        
        return low_neurons
    
    def print_gradient_analysis(self, gradient_stats):
        """æ‰“å°æ¢¯åº¦åˆ†æç»“æœ"""
        print("="*80)
        print("å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†å¸ƒåˆ†æ")
        print("="*80)
        
        if not gradient_stats:
            print("æ²¡æœ‰æ”¶é›†åˆ°æ¢¯åº¦æ•°æ®")
            return
        
        for layer_name, stats in gradient_stats.items():
            if not stats.get('values'):
                continue
                
            print(f"\nå±‚: {layer_name}")
            print(f"  ç¥ç»å…ƒæ•°é‡: {stats['num_neurons']:,}")
            print(f"  æ¢¯åº¦ç»Ÿè®¡:")
            print(f"    å‡å€¼: {stats['mean']:.8f}")
            print(f"    æ ‡å‡†å·®: {stats['std']:.8f}")
            print(f"    æœ€å°å€¼: {stats['min']:.8f}")
            print(f"    æœ€å¤§å€¼: {stats['max']:.8f}")
            print(f"    ä¸­ä½æ•°: {stats['median']:.8f}")
            print(f"  æ¢¯åº¦åˆ†å¸ƒ:")
            print(f"    25%åˆ†ä½æ•°: {stats['p25']:.8f}")
            print(f"    75%åˆ†ä½æ•°: {stats['p75']:.8f}")
            print(f"    95%åˆ†ä½æ•°: {stats['p95']:.8f}")
            print("-"*60)
        
        # åˆ†æä½æ¢¯åº¦ç¥ç»å…ƒ
        print("\nä½æ¢¯åº¦ç¥ç»å…ƒåˆ†æ:")
        for ratio in [0.05, 0.1, 0.2]:
            low_neurons = self.get_low_gradient_neurons(gradient_stats, ratio)
            print(f"  æ¢¯åº¦æœ€ä½ {ratio*100:.1f}% çš„ç¥ç»å…ƒæ•°é‡: {len(low_neurons)}")
            
            if low_neurons:
                # æŒ‰å±‚åˆ†ç»„ç»Ÿè®¡
                layer_counts = {}
                for neuron in low_neurons:
                    layer = neuron['layer']
                    if layer not in layer_counts:
                        layer_counts[layer] = 0
                    layer_counts[layer] += 1
                
                for layer, count in layer_counts.items():
                    print(f"    {layer}: {count} ä¸ª")
        
        print("="*80)
        
    class GradientAnalyzer:
    def __init__(self, model, prune_ratio=0.1):
        self.model = model
        self.prune_ratio = prune_ratio
        self.gradient_records = defaultdict(list)
        
        # ä¸ºæ‰€æœ‰å…¨è¿æ¥å±‚æ³¨å†Œæ¢¯åº¦é’©å­
        for name, module in model.named_modules():
            if isinstance(module, nn.Linear):
                hook = self.make_hook(name)
                module.weight.register_hook(hook)
    
    def make_hook(self, layer_name):
        """åˆ›å»ºæ¢¯åº¦é’©å­"""
        def gradient_hook(grad):
            # è®¡ç®—æ¯ä¸ªè¾“å‡ºç¥ç»å…ƒçš„å¹³å‡æ¢¯åº¦å¹…åº¦
            # å¯¹äºå…¨è¿æ¥å±‚ï¼Œå¯¹è¾“å…¥ç»´åº¦å–å¹³å‡
            if grad.dim() > 1:
                grad_mag = grad.abs().mean(dim=1)  # è¾“å‡ºå½¢çŠ¶: [out_features]
            else:
                grad_mag = grad.abs()
            self.gradient_records[layer_name].append(grad_mag.detach().cpu())
        return gradient_hook
    
    def get_low_grad_neurons(self):
        """è·å–ä½æ¢¯åº¦ç¥ç»å…ƒä¿¡æ¯"""
        all_neurons = []
        
        # éå†æ‰€æœ‰è®°å½•çš„å…¨è¿æ¥å±‚
        for layer_name, grad_list in self.gradient_records.items():
            if not grad_list:
                continue
                
            # åˆå¹¶æ‰€æœ‰æ¢¯åº¦è®°å½•
            stacked_grads = torch.stack(grad_list)
            
            # è®¡ç®—å¹³å‡æ¢¯åº¦ (è·¨æ—¶é—´å’Œæ‰¹æ¬¡)
            if stacked_grads.dim() > 1:
                neuron_avg_grad = stacked_grads.mean(dim=0).mean(dim=0)
            else:
                neuron_avg_grad = stacked_grads.mean()
            
            # æ”¶é›†è¯¥å±‚çš„ç¥ç»å…ƒæ¢¯åº¦ä¿¡æ¯
            for neuron_idx, grad_value in enumerate(neuron_avg_grad):
                all_neurons.append((layer_name, neuron_idx, grad_value.item()))
        
        # æŒ‰æ¢¯åº¦å€¼æ’åº
        all_neurons.sort(key=lambda x: x[2])
        
        # é€‰æ‹©æ¢¯åº¦æœ€å°çš„ç¥ç»å…ƒ
        num_to_prune = int(len(all_neurons) * self.prune_ratio)
        return all_neurons[:num_to_prune]
    
    def prune_neurons(self, neurons_to_prune):
        """æ‰§è¡Œç¥ç»å…ƒå‰ªæ"""
        for layer_name, neuron_idx, _ in neurons_to_prune:
            # æ‰¾åˆ°å¯¹åº”çš„å±‚
            module = None
            for name, mod in self.model.named_modules():
                if name == layer_name and isinstance(mod, nn.Linear):
                    module = mod
                    break
            
            if module:
                # æ‰§è¡Œå‰ªæï¼šå°†ç¥ç»å…ƒçš„æƒé‡ç½®é›¶
                with torch.no_grad():
                    module.weight.data[neuron_idx] = 0
                    if module.bias is not None:
                        module.bias.data[neuron_idx] = 0
                    
                    # å¯é€‰ï¼šå‰ªæä¸‹æ¸¸è¿æ¥
                    self._prune_downstream(module, layer_name, neuron_idx)
    
    def _prune_downstream(self, pruned_module, layer_name, neuron_idx):
        """å‰ªæä¸‹æ¸¸å±‚çš„è¿æ¥"""
        # æŸ¥æ‰¾æ‰€æœ‰ä½¿ç”¨è¯¥å±‚è¾“å‡ºçš„æ¨¡å—
        downstream_layers = []
        
        # æ£€æŸ¥æ‰€æœ‰åç»­å±‚
        current_layer_found = False
        for name, module in self.model.named_modules():
            if name == layer_name:
                current_layer_found = True
                continue
            
            if current_layer_found and isinstance(module, (nn.Linear, LIFNeuron)):
                # çº¿æ€§å±‚ç›´æ¥ä½¿ç”¨è¯¥è¾“å‡º
                if isinstance(module, nn.Linear):
                    if module.weight.shape[1] == pruned_module.weight.shape[0]:
                        downstream_layers.append(module)
                # å¦‚æœæ˜¯LIFNeuronï¼ŒæŸ¥æ‰¾å…¶å‰é¢çš„çº¿æ€§å±‚
                elif isinstance(module, LIFNeuron):
                    # è·å–å‰é¢çš„çº¿æ€§å±‚
                    for prev_name, prev_module in self.model.named_modules():
                        if prev_name == name.replace("lif", "fc") and isinstance(prev_module, nn.Linear):
                            if prev_module.weight.shape[1] == pruned_module.weight.shape[0]:
                                downstream_layers.append(prev_module)
        
        # å‰ªæä¸‹æ¸¸å±‚å¯¹åº”çš„è¾“å…¥æƒé‡
        for down_layer in downstream_layers:
            with torch.no_grad():
                # å‰ªæè¾“å…¥è¿æ¥
                down_layer.weight.data[:, neuron_idx] = 0
        
    
    def cleanup_hooks(self):
        """æ¸…ç†æ¢¯åº¦é’©å­"""
        for handle in self.gradient_hooks.values():
            handle.remove()
        self.gradient_hooks = {}
        self.gradient_records = {}

class OutputRedirector:
    """è¾“å‡ºé‡å®šå‘å™¨ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è·å–VGG16å‚æ•°å’Œæ¢¯åº¦')
    parser.add_argument('--batch_size', default=32, type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', default='0', type=str, help='è®¾å¤‡')
    parser.add_argument('--seed', default=42, type=int, help='éšæœºç§å­')
    parser.add_argument('--mode', choices=['ann', 'snn'], default='snn', help='æ¨¡å¼')
    parser.add_argument('--num_batches', default=5, type=int, help='æ¢¯åº¦åˆ†æçš„æ‰¹æ¬¡æ•°')

    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºé‡å®šå‘ï¼ˆé»˜è®¤ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"gradient_analysis_{args.mode}_{timestamp}.txt"
    output_redirector = OutputRedirector(filename)
    sys.stdout = output_redirector
    print(f"è¾“å‡ºå°†ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
    
    # è®¾ç½®ç¯å¢ƒ
    os.environ["CUDA_VISIBLE_DEVICES"] = args.device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    seed_all(args.seed)
    
    print(f"è®¾å¤‡: {device}, éšæœºç§å­: {args.seed}")
    print(f"åˆ†ææ¨¡å¼: {args.mode}")
    print(f"æ¢¯åº¦åˆ†ææ‰¹æ¬¡æ•°: {args.num_batches}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºVGG16æ¨¡å‹...")
        model = modelpool('vgg16', 'cifar10')
        
        # ç›´æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = '/root/autodl-tmp/0-ANN2SNN-Allinone/2-ANN_SNN_QCFS-SRP/cifar10-checkpoints/vgg16_wd[0.0005].pth'
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # å¤„ç†æ—§ç‰ˆæœ¬state_dictçš„å…¼å®¹æ€§
        keys = list(state_dict.keys())
        for k in keys:
            if "relu.up" in k:
                state_dict[k[:-7]+'act.thresh'] = state_dict.pop(k)
            elif "up" in k:
                state_dict[k[:-2]+'thresh'] = state_dict.pop(k)
        
        model.load_state_dict(state_dict)
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        if args.mode == 'snn':
            model.set_T(8)
            model.set_L(4)
            print("è®¾ç½®ä¸ºSNNæ¨¡å¼")
        else:
            model.set_T(0)
            print("è®¾ç½®ä¸ºANNæ¨¡å¼")
        
        model.to(device)
        model.train()
        
        # åŠ è½½æ•°æ®
        print("åŠ è½½CIFAR10æ•°æ®é›†...")
        train_loader, test_loader = datapool('cifar10', args.batch_size)
        
        # è·å–ä¸€æ‰¹æ•°æ®
        data_iter = iter(train_loader)
        images, labels = next(data_iter)
        images, labels = images.to(device), labels.to(device)
        
        print(f"è¾“å…¥å½¢çŠ¶: {images.shape}, æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        
        # å‰å‘ä¼ æ’­
        print("æ‰§è¡Œå‰å‘ä¼ æ’­...")
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01)
        
        optimizer.zero_grad()
        outputs = model(images)
        
        # å¤„ç†SNNè¾“å‡º
        if len(outputs.shape) > 2:
            outputs = outputs.mean(0)
        
        loss = criterion(outputs, labels)
        print(f"æŸå¤±: {loss.item():.6f}")
        
        # åå‘ä¼ æ’­
        print("æ‰§è¡Œåå‘ä¼ æ’­...")
        loss.backward()
        
        # åªæ‰“å°IFå±‚ä¿¡æ¯
        print_if_layers_only(model)
        print_all_if_module_info(model)
        
        # åˆ†æå…¨è¿æ¥å±‚æ¢¯åº¦ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        print("\n" + "="*80)
        print("å¼€å§‹å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†æ")
        print("="*80)
        
        # åˆ›å»ºæ¢¯åº¦åˆ†æå™¨
        analyzer = GradientAnalyzer(model)
        
        try:
            # åˆ†ææ¢¯åº¦åˆ†å¸ƒ
            gradient_stats = analyzer.analyze_gradients(
                train_loader, 
                criterion, 
                num_batches=args.num_batches
            )
            
            # æ‰“å°åˆ†æç»“æœ
            analyzer.print_gradient_analysis(gradient_stats)
            
            # ä¿å­˜å„å±‚æ¢¯åº¦ä¿¡æ¯åˆ°CSVæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            for layer_name, stats in gradient_stats.items():
                if not stats.get('values'):
                    continue
                
                # è·å–è¯¥å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼ˆæ€»æ¢¯åº¦æ•°é™¤ä»¥batchæ•°ï¼‰
                num_neurons = len(stats['values']) // args.num_batches
                
                # é‡å¡‘æ•°æ®ä¸º [num_neurons, num_batches] çš„å½¢çŠ¶
                gradient_values = np.array(stats['values']).reshape(num_neurons, args.num_batches)
                
                # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„å¹³å‡æ¢¯åº¦å€¼
                mean_gradients = np.mean(gradient_values, axis=1)
                
                # åˆ›å»ºDataFrame
                df = pd.DataFrame({
                    'neuron_index': range(num_neurons)
                })
                
                # æ·»åŠ æ¯ä¸ªbatchçš„æ¢¯åº¦å€¼åˆ—
                for i in range(args.num_batches):
                    df[f'gradient_batch_{i+1}'] = gradient_values[:, i]
                
                # æ·»åŠ å¹³å‡æ¢¯åº¦å€¼åˆ—
                df['gradient_mean'] = mean_gradients
                
                # ç”Ÿæˆæ–‡ä»¶å
                filename = f"gradient_analysis_{layer_name}_{timestamp}.csv"
                
                # ä¿å­˜åˆ°CSV
                df.to_csv(filename, index=False)
                print(f"å·²ä¿å­˜{layer_name}å±‚çš„æ¢¯åº¦ä¿¡æ¯åˆ°: {filename}")
                print(f"  ç¥ç»å…ƒæ•°é‡: {num_neurons}")
                print(f"  æ¯ä¸ªç¥ç»å…ƒåŒ…å«{args.num_batches}ä¸ªbatchçš„æ¢¯åº¦å€¼å’Œå¹³å‡å€¼")
            
            # è¯¦ç»†åˆ†æä½æ¢¯åº¦ç¥ç»å…ƒ
            print("\n" + "="*80)
            print("ä½æ¢¯åº¦ç¥ç»å…ƒè¯¦ç»†åˆ†æ")
            print("="*80)
            
            for ratio in [0.05, 0.1, 0.15, 0.2]:
                low_neurons = analyzer.get_low_gradient_neurons(gradient_stats, ratio)
                print(f"\næ¢¯åº¦æœ€ä½ {ratio*100:.1f}% çš„ç¥ç»å…ƒè¯¦æƒ…:")
                
                if low_neurons:
                    # æŒ‰å±‚åˆ†ç»„æ˜¾ç¤º
                    layer_groups = {}
                    for neuron in low_neurons:
                        layer = neuron['layer']
                        if layer not in layer_groups:
                            layer_groups[layer] = []
                        layer_groups[layer].append(neuron)
                    
                    for layer, neurons in layer_groups.items():
                        print(f"  {layer}: {len(neurons)} ä¸ªç¥ç»å…ƒ")
                        # æ˜¾ç¤ºå‰5ä¸ªæœ€ä½æ¢¯åº¦çš„ç¥ç»å…ƒ
                        for i, neuron in enumerate(sorted(neurons, key=lambda x: x['grad_value'])[:5]):
                            print(f"    #{i+1}: ç¥ç»å…ƒ{neuron['neuron_index']}, æ¢¯åº¦={neuron['grad_value']:.8f}, ç™¾åˆ†ä½={neuron['grad_percentile']:.3f}")
                else:
                    print("  æ— æ•°æ®")
            
        finally:
            # æ¸…ç†æ¢¯åº¦é’©å­
            analyzer.cleanup_hooks()
        
        print("\nâœ… å®Œæˆ!")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("python 0612get_grad.py --mode snn  # SNNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯å’Œæ¢¯åº¦åˆ†æ")
        print("python 0612get_grad.py --mode ann  # ANNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯å’Œæ¢¯åº¦åˆ†æ")
        print("python 0612get_grad.py --mode snn --num_batches 10  # æŒ‡å®šåˆ†ææ‰¹æ¬¡æ•°")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¢å¤æ ‡å‡†è¾“å‡ºå¹¶å…³é—­æ–‡ä»¶
        if output_redirector is not None:
            sys.stdout = output_redirector.terminal
            output_redirector.close()
            print(f"è¾“å‡ºå·²ä¿å­˜åˆ°: {filename}")

if __name__ == "__main__":
    main() 