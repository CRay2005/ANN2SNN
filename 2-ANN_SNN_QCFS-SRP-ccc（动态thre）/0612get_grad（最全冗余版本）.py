#!/usr/bin/env python3


import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import argparse
import os
import sys
from datetime import datetime
from Models import modelpool
from Preprocess import datapool
from utils import seed_all
import pandas as pd

def get_params_grad(model):
    """
    è·å–æ¨¡å‹å‚æ•°å’Œå¯¹åº”çš„æ¢¯åº¦
    å‚è€ƒè‡ªhessian_weight_importance.py
    """
    params = []
    grads = []
    for param in model.parameters():
        if not param.requires_grad:
            continue
        params.append(param)
        grads.append(0. if param.grad is None else param.grad + 0.)
    return params, grads

def print_params_and_gradients(model):
    """æ‰“å°æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("VGG16æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯")
    print("="*80)
    
    params, grads = get_params_grad(model)
    
    print(f"æ€»å…±æœ‰ {len(params)} ä¸ªéœ€è¦æ¢¯åº¦çš„å‚æ•°")
    print("-"*80)
    
    total_params = 0
    total_grad_norm = 0.0
    
    for i, (param, grad) in enumerate(zip(params, grads)):
        param_count = param.numel()
        total_params += param_count
        
        # æ¢¯åº¦ç»Ÿè®¡
        if torch.is_tensor(grad):
            grad_norm = grad.norm().item()
            grad_mean = grad.mean().item()
            grad_std = grad.std().item()
            non_zero_elements = (grad != 0).sum().item()
            total_grad_norm += grad_norm ** 2
        else:
            grad_norm = grad_mean = grad_std = 0.0
            non_zero_elements = 0
        
        print(f"å‚æ•° {i+1:2d}: å½¢çŠ¶={list(param.shape)}, æ•°é‡={param_count:,}")
        print(f"  å‚æ•°ç»Ÿè®¡: å‡å€¼={param.mean().item():.6f}, æ ‡å‡†å·®={param.std().item():.6f}")
        print(f"  æ¢¯åº¦ç»Ÿè®¡: èŒƒæ•°={grad_norm:.6f}, å‡å€¼={grad_mean:.6f}, æ ‡å‡†å·®={grad_std:.6f}")
        print(f"  éé›¶æ¢¯åº¦: {non_zero_elements:,}/{param_count:,} ({100*non_zero_elements/param_count:.2f}%)")
        print("-"*40)
    
    total_grad_norm = np.sqrt(total_grad_norm)
    print(f"\næ€»ç»“: {total_params:,} ä¸ªå‚æ•°, æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")
    print("="*80)

def print_if_module_info(model):
    """æ‰“å°æ‰€æœ‰IFæ¨¡å—çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬é˜ˆå€¼å‚æ•°å’Œæ¢¯åº¦ä¿¡æ¯"""
    print("="*80)
    print("IFæ¨¡å—è¯¦ç»†ä¿¡æ¯")
    print("="*80)
    
    from Models.layer import IF
    
    if_module_count = 0
    
    # é€šè¿‡æ¨¡å—æŸ¥æ‰¾IFå±‚
    for name, module in model.named_modules():
        if isinstance(module, IF):
            if_module_count += 1
            print(f"IFæ¨¡å—: {name}")
            print(f"  é˜ˆå€¼(thresh): {module.thresh.item():.6f}")
            # print(f"  gammaå‚æ•°: {module.gama}")
            # print(f"  æ—¶é—´æ­¥æ•°(T): {module.T}")
            # print(f"  é‡åŒ–çº§åˆ«(L): {module.L}")
            
            # æ‰“å°é˜ˆå€¼å‚æ•°çš„æ¢¯åº¦
            if module.thresh.grad is not None:
                thresh_grad = module.thresh.grad.item()
                print(f"  é˜ˆå€¼æ¢¯åº¦: {thresh_grad:.6f}")
            else:
                print(f"  é˜ˆå€¼æ¢¯åº¦: None")
            
            print("-"*60)
    
    # æ€»ç»“
    if if_module_count == 0:
        print("æœªæ‰¾åˆ°IFæ¨¡å—")
    else:
        print(f"æ€»å…±æ‰¾åˆ° {if_module_count} ä¸ªIFæ¨¡å—")
    print("="*80)

def new_print_if_module_info(model):
    """æ‰“å°æ‰€æœ‰IFæ¨¡å—çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¾“å…¥æ¢¯åº¦å’Œè¾“å‡ºæ¢¯åº¦"""
    print("="*80)
    print("IFæ¨¡å—è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«è¾“å…¥è¾“å‡ºæ¢¯åº¦ï¼‰")
    print("="*80)
    
    from Models.layer import IF
    
    if_module_count = 0
    
    # å­˜å‚¨æ¢¯åº¦ä¿¡æ¯çš„å­—å…¸
    gradient_info = {}
    
    # ä¸ºæ¯ä¸ªIFå±‚æ³¨å†Œé’©å­æ¥æ•è·è¾“å…¥å’Œè¾“å‡ºæ¢¯åº¦
    def register_if_hooks():
        hooks = []
        
        for name, module in model.named_modules():
            if isinstance(module, IF):
                # å­˜å‚¨è¯¥æ¨¡å—çš„æ¢¯åº¦ä¿¡æ¯
                gradient_info[name] = {
                    'input_grad': None,
                    'output_grad': None,
                    'module': module
                }
                
                # æ³¨å†Œè¾“å‡ºæ¢¯åº¦é’©å­
                def create_output_hook(module_name):
                    def output_hook(module, grad_input, grad_output):
                        if grad_output[0] is not None:
                            gradient_info[module_name]['output_grad'] = grad_output[0].detach().clone()
                        
                        # æ‰“å°è¯¦ç»†çš„æ¢¯åº¦ä¿¡æ¯
                        print(f"\n{module_name} æ¢¯åº¦ä¿¡æ¯:")
                        print(f"  grad_output (dL/dy): {grad_output[0].shape if grad_output[0] is not None else 'None'}")
                        
                        # é’ˆå¯¹IFå±‚çš„ç‰¹æ®Šæ€§ï¼šåªæœ‰è¾“å…¥æ¢¯åº¦ï¼Œæ²¡æœ‰æƒé‡å’Œåç½®æ¢¯åº¦
                        if isinstance(module, IF):
                            print(f"  grad_input (dL/dx): {[g.shape for g in grad_input if g is not None]}")
                            print(f"  ğŸ“ IFå±‚è¯´æ˜: åªæœ‰è¾“å…¥æ¢¯åº¦dL/dxï¼Œæ— æƒé‡æ¢¯åº¦dL/dWå’Œåç½®æ¢¯åº¦dL/db")
                        else:
                            print(f"  grad_input (dL/dx, dL/dW, dL/db): {[g.shape for g in grad_input if g is not None]}")
                        
                        # è¯¦ç»†åˆ†ægrad_inputçš„æ¯ä¸ªå…ƒç´ 
                        for i, grad in enumerate(grad_input):
                            if grad is not None:
                                if isinstance(module, IF):
                                    print(f"    grad_input[{i}] (dL/dx): shape={grad.shape}, norm={grad.norm().item():.6f}, mean={grad.mean().item():.6f}")
                                else:
                                    if i == 0:
                                        grad_type = "dL/dx"
                                    elif i == 1:
                                        grad_type = "dL/dW"
                                    elif i == 2:
                                        grad_type = "dL/db"
                                    else:
                                        grad_type = f"dL/dparam{i}"
                                    print(f"    grad_input[{i}] ({grad_type}): shape={grad.shape}, norm={grad.norm().item():.6f}, mean={grad.mean().item():.6f}")
                            else:
                                if isinstance(module, IF):
                                    print(f"    grad_input[{i}] (dL/dx): None")
                                else:
                                    print(f"    grad_input[{i}]: None")
                        
                        # åˆ†ægrad_output
                        if grad_output[0] is not None:
                            print(f"  grad_output[0]: shape={grad_output[0].shape}, norm={grad_output[0].norm().item():.6f}, mean={grad_output[0].mean().item():.6f}")
                        
                        # é’ˆå¯¹IFå±‚ï¼Œé¢å¤–æ˜¾ç¤ºé˜ˆå€¼æ¢¯åº¦ä¿¡æ¯
                        if isinstance(module, IF) and module.thresh.grad is not None:
                            print(f"  ğŸ¯ IFå±‚é˜ˆå€¼æ¢¯åº¦ (dL/dthresh): {module.thresh.grad.item():.6f}")
                        
                        print("-" * 40)
                    return output_hook
                
                # æ³¨å†Œè¾“å…¥æ¢¯åº¦é’©å­
                def create_input_hook(module_name):
                    def input_hook(module, grad_input, grad_output):
                        if grad_input[0] is not None:
                            gradient_info[module_name]['input_grad'] = grad_input[0].detach().clone()
                    return input_hook
                
                output_hook = module.register_full_backward_hook(create_output_hook(name))
                input_hook = module.register_full_backward_hook(create_input_hook(name))
                hooks.extend([output_hook, input_hook])
        
        return hooks
    
    # æ³¨å†Œé’©å­
    hooks = register_if_hooks()
    
    try:
        # é€šè¿‡æ¨¡å—æŸ¥æ‰¾IFå±‚å¹¶æ‰“å°ä¿¡æ¯
        for name, module in model.named_modules():
            if isinstance(module, IF):
                if_module_count += 1
                print(f"IFæ¨¡å—: {name}")
                print(f"  é˜ˆå€¼(thresh): {module.thresh.item():.6f}")
                print(f"  æ—¶é—´æ­¥æ•°(T): {module.T}")
                print(f"  é‡åŒ–çº§åˆ«(L): {module.L}")
                print(f"  ä»£ç†æ¢¯åº¦ç±»å‹: {module.surrogate_grad}")
                print(f"  ç¼©æ”¾å› å­: {module.scale}")
                
                # æ‰“å°é˜ˆå€¼å‚æ•°çš„æ¢¯åº¦
                if module.thresh.grad is not None:
                    thresh_grad = module.thresh.grad.item()
                    thresh_grad_norm = module.thresh.grad.norm().item()
                    print(f"  é˜ˆå€¼æ¢¯åº¦: {thresh_grad:.6f}")
                    print(f"  é˜ˆå€¼æ¢¯åº¦èŒƒæ•°: {thresh_grad_norm:.6f}")
                else:
                    print(f"  é˜ˆå€¼æ¢¯åº¦: None")
                
                # æ‰“å°è¾“å…¥æ¢¯åº¦ä¿¡æ¯
                input_grad = gradient_info[name]['input_grad']
                if input_grad is not None:
                    print(f"  è¾“å…¥æ¢¯åº¦:")
                    print(f"    å½¢çŠ¶: {list(input_grad.shape)}")
                    print(f"    èŒƒæ•°: {input_grad.norm().item():.6f}")
                    print(f"    å‡å€¼: {input_grad.mean().item():.6f}")
                    print(f"    æ ‡å‡†å·®: {input_grad.std().item():.6f}")
                    print(f"    æœ€å°å€¼: {input_grad.min().item():.6f}")
                    print(f"    æœ€å¤§å€¼: {input_grad.max().item():.6f}")
                    
                    # è®¡ç®—éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (input_grad != 0).float().mean().item()
                    print(f"    éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                    
                    # è®¡ç®—æ¢¯åº¦åˆ†å¸ƒ
                    grad_abs = input_grad.abs()
                    print(f"    æ¢¯åº¦åˆ†å¸ƒ:")
                    print(f"      25%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.25).item():.6f}")
                    print(f"      50%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.50).item():.6f}")
                    print(f"      75%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.75).item():.6f}")
                    print(f"      95%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.95).item():.6f}")
                else:
                    print(f"  è¾“å…¥æ¢¯åº¦: None")
                
                # æ‰“å°è¾“å‡ºæ¢¯åº¦ä¿¡æ¯
                output_grad = gradient_info[name]['output_grad']
                if output_grad is not None:
                    print(f"  è¾“å‡ºæ¢¯åº¦:")
                    print(f"    å½¢çŠ¶: {list(output_grad.shape)}")
                    print(f"    èŒƒæ•°: {output_grad.norm().item():.6f}")
                    print(f"    å‡å€¼: {output_grad.mean().item():.6f}")
                    print(f"    æ ‡å‡†å·®: {output_grad.std().item():.6f}")
                    print(f"    æœ€å°å€¼: {output_grad.min().item():.6f}")
                    print(f"    æœ€å¤§å€¼: {output_grad.max().item():.6f}")
                    
                    # è®¡ç®—éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (output_grad != 0).float().mean().item()
                    print(f"    éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                    
                    # è®¡ç®—æ¢¯åº¦åˆ†å¸ƒ
                    grad_abs = output_grad.abs()
                    print(f"    æ¢¯åº¦åˆ†å¸ƒ:")
                    print(f"      25%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.25).item():.6f}")
                    print(f"      50%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.50).item():.6f}")
                    print(f"      75%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.75).item():.6f}")
                    print(f"      95%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.95).item():.6f}")
                else:
                    print(f"  è¾“å‡ºæ¢¯åº¦: None")
                
                print("-"*60)
        
        # æ€»ç»“
        if if_module_count == 0:
            print("æœªæ‰¾åˆ°IFæ¨¡å—")
        else:
            print(f"æ€»å…±æ‰¾åˆ° {if_module_count} ä¸ªIFæ¨¡å—")
            print(f"å·²æ•è·è¾“å…¥å’Œè¾“å‡ºæ¢¯åº¦ä¿¡æ¯")
    
    finally:
        # æ¸…ç†é’©å­
        for hook in hooks:
            hook.remove()
    
    print("="*80)

def get_if_layer_input_output_gradients(model, dataloader, criterion):
    """è·å–IFå±‚çš„è¾“å…¥å’Œè¾“å‡ºæ¢¯åº¦ï¼ˆéœ€è¦å®Œæ•´çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼‰"""
    print("="*80)
    print("IFå±‚è¾“å…¥è¾“å‡ºæ¢¯åº¦åˆ†æ")
    print("="*80)
    
    from Models.layer import IF
    
    # å­˜å‚¨æ¢¯åº¦ä¿¡æ¯çš„å­—å…¸
    gradient_info = {}
    
    # ä¸ºæ¯ä¸ªIFå±‚æ³¨å†Œé’©å­
    def register_gradient_hooks():
        hooks = []
        
        for name, module in model.named_modules():
            if isinstance(module, IF):
                gradient_info[name] = {
                    'input_grad': None,
                    'output_grad': None,
                    'module': module
                }
                
                # æ³¨å†Œè¾“å‡ºæ¢¯åº¦é’©å­
                def create_output_hook(module_name):
                    def output_hook(module, grad_input, grad_output):
                        if grad_output[0] is not None:
                            gradient_info[module_name]['output_grad'] = grad_output[0].detach().clone()

                        if grad_input[0] is not None:
                            gradient_info[module_name]['input_grad'] = grad_input[0].detach().clone()

                        # æ‰“å°è¯¦ç»†çš„æ¢¯åº¦ä¿¡æ¯
                        print(f"\n{module_name} æ¢¯åº¦ä¿¡æ¯:")
                        print(f"grad_output (dL/dy): {grad_output[0].shape if grad_output[0] is not None else 'None'}")
                        
                        # é’ˆå¯¹IFå±‚çš„ç‰¹æ®Šæ€§ï¼šåªæœ‰è¾“å…¥æ¢¯åº¦ï¼Œæ²¡æœ‰æƒé‡å’Œåç½®æ¢¯åº¦
                        if isinstance(module, IF):
                            print(f"  grad_input (dL/dx): {[g.shape for g in grad_input if g is not None]}")
                            print(f"  ğŸ“ IFå±‚è¯´æ˜: åªæœ‰è¾“å…¥æ¢¯åº¦dL/dxï¼Œæ— æƒé‡æ¢¯åº¦dL/dWå’Œåç½®æ¢¯åº¦dL/db")
                        else:
                            print(f"  grad_input (dL/dx, dL/dW, dL/db): {[g.shape for g in grad_input if g is not None]}")
                        
                        # # è¯¦ç»†åˆ†ægrad_inputçš„æ¯ä¸ªå…ƒç´ 
                        # for i, grad in enumerate(grad_input):
                        #     if grad is not None:
                        #         if isinstance(module, IF):
                        #             print(f"    grad_input[{i}] (dL/dx): shape={grad.shape}, norm={grad.norm().item():.6f}, mean={grad.mean().item():.6f}")
                        #         else:
                        #             if i == 0:
                        #                 grad_type = "dL/dx"
                        #             elif i == 1:
                        #                 grad_type = "dL/dW"
                        #             elif i == 2:
                        #                 grad_type = "dL/db"
                        #             else:
                        #                 grad_type = f"dL/dparam{i}"
                        #             print(f"    grad_input[{i}] ({grad_type}): shape={grad.shape}, norm={grad.norm().item():.6f}, mean={grad.mean().item():.6f}")
                        #     else:
                        #         if isinstance(module, IF):
                        #             print(f"    grad_input[{i}] (dL/dx): None")
                        #         else:
                        #             print(f"    grad_input[{i}]: None")
                        
                        # åˆ†ægrad_output
                        if grad_output[0] is not None:
                            print(f"  grad_output[0]: shape={grad_output[0].shape}, norm={grad_output[0].norm().item():.6f}, mean={grad_output[0].mean().item():.6f}")
                        
                        # é’ˆå¯¹IFå±‚ï¼Œé¢å¤–æ˜¾ç¤ºé˜ˆå€¼æ¢¯åº¦ä¿¡æ¯
                        if isinstance(module, IF) and module.thresh.grad is not None:
                            print(f"  ğŸ¯ IFå±‚é˜ˆå€¼æ¢¯åº¦ (dL/dthresh): {module.thresh.grad.item():.6f}")
                        
                        print("-" * 40)
                    return output_hook
                
                hook = module.register_full_backward_hook(create_output_hook(name))
                hooks.append(hook)
        
        return hooks
    
    # æ³¨å†Œé’©å­
    hooks = register_gradient_hooks()
    
    try:
        # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # è·å–ä¸€æ‰¹æ•°æ®
        data_iter = iter(dataloader)
        inputs, targets = next(data_iter)
        inputs, targets = inputs.to(next(model.parameters()).device), targets.to(next(model.parameters()).device)
        
        # æ¸…ç©ºæ¢¯åº¦
        model.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(inputs)
        
        # å¤„ç†SNNè¾“å‡º
        if len(outputs.shape) > 2:
            outputs = outputs.mean(0)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, targets)
        print(f"æŸå¤±: {loss.item():.6f}")
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # åˆ†ææ¯ä¸ªIFå±‚
        if_module_count = 0
        for name, module in model.named_modules():
            if isinstance(module, IF):
                if_module_count += 1
                print(f"IFæ¨¡å—: {name}")
                print(f"  é˜ˆå€¼(thresh): {module.thresh.item():.6f}")
                print(f"  æ—¶é—´æ­¥æ•°(T): {module.T}")
                print(f"  é‡åŒ–çº§åˆ«(L): {module.L}")
                
                # æ‰“å°é˜ˆå€¼æ¢¯åº¦
                if module.thresh.grad is not None:
                    thresh_grad = module.thresh.grad.item()
                    thresh_grad_norm = module.thresh.grad.norm().item()
                    print(f"  é˜ˆå€¼æ¢¯åº¦: {thresh_grad:.6f}")
                    print(f"  é˜ˆå€¼æ¢¯åº¦èŒƒæ•°: {thresh_grad_norm:.6f}")
                else:
                    print(f"  é˜ˆå€¼æ¢¯åº¦: None")
                
                # æ‰“å°è¾“å‡ºæ¢¯åº¦
                output_grad = gradient_info[name]['output_grad']
                if output_grad is not None:
                    print(f"  è¾“å‡ºæ¢¯åº¦:")
                    print(f"    å½¢çŠ¶: {list(output_grad.shape)}")
                    print(f"    èŒƒæ•°: {output_grad.norm().item():.6f}")
                    print(f"    å‡å€¼: {output_grad.mean().item():.6f}")
                    print(f"    æ ‡å‡†å·®: {output_grad.std().item():.6f}")
                    print(f"    æœ€å°å€¼: {output_grad.min().item():.6f}")
                    print(f"    æœ€å¤§å€¼: {output_grad.max().item():.6f}")
                    
                    # è®¡ç®—éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (output_grad != 0).float().mean().item()
                    print(f"    éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                    
                    # è®¡ç®—æ¢¯åº¦åˆ†å¸ƒ
                    grad_abs = output_grad.abs()
                    print(f"    æ¢¯åº¦åˆ†å¸ƒ:")
                    print(f"      25%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.25).item():.6f}")
                    print(f"      50%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.50).item():.6f}")
                    print(f"      75%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.75).item():.6f}")
                    print(f"      95%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.95).item():.6f}")
                else:
                    print(f"  è¾“å‡ºæ¢¯åº¦: None")
                
                # å°è¯•è·å–è¾“å…¥æ¢¯åº¦ï¼ˆé€šè¿‡æ£€æŸ¥è¾“å…¥å¼ é‡çš„æ¢¯åº¦ï¼‰
                # æ‰“å°è¾“å…¥æ¢¯åº¦ä¿¡æ¯
                input_grad = gradient_info[name]['input_grad']
                if input_grad is not None:
                    print(f"  è¾“å…¥æ¢¯åº¦:")
                    print(f"    å½¢çŠ¶: {list(input_grad.shape)}")
                    print(f"    èŒƒæ•°: {input_grad.norm().item():.6f}")
                    print(f"    å‡å€¼: {input_grad.mean().item():.6f}")
                    print(f"    æ ‡å‡†å·®: {input_grad.std().item():.6f}")
                    print(f"    æœ€å°å€¼: {input_grad.min().item():.6f}")
                    print(f"    æœ€å¤§å€¼: {input_grad.max().item():.6f}")
                    
                    # è®¡ç®—éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (input_grad != 0).float().mean().item()
                    print(f"    éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                    
                    # è®¡ç®—æ¢¯åº¦åˆ†å¸ƒ
                    grad_abs = input_grad.abs()
                    print(f"    æ¢¯åº¦åˆ†å¸ƒ:")
                    print(f"      25%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.25).item():.6f}")
                    print(f"      50%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.50).item():.6f}")
                    print(f"      75%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.75).item():.6f}")
                    print(f"      95%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.95).item():.6f}")
                else:
                    print(f"  è¾“å…¥æ¢¯åº¦: None")
                print("-"*60)
        
        # æ€»ç»“
        if if_module_count == 0:
            print("æœªæ‰¾åˆ°IFæ¨¡å—")
        else:
            print(f"æ€»å…±æ‰¾åˆ° {if_module_count} ä¸ªIFæ¨¡å—")
            print(f"å·²æˆåŠŸæ•è·è¾“å‡ºæ¢¯åº¦ä¿¡æ¯")
    
    finally:
        # æ¸…ç†é’©å­
        for hook in hooks:
            hook.remove()
    
    print("="*80)

class GradientAnalyzer:
    """å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†æå™¨ï¼ˆå‚è€ƒgradient_cray.pyï¼‰"""
    def __init__(self, model):
        self.model = model
        self.gradient_hooks = {}
        self.gradient_records = {}
        
    def register_gradient_hooks(self):
        """ä¸ºæ‰€æœ‰å…¨è¿æ¥å±‚æ³¨å†Œæ¢¯åº¦è®°å½•é’©å­"""
        print("æ³¨å†Œå…¨è¿æ¥å±‚æ¢¯åº¦é’©å­...")
        
        # ç§»é™¤ç°æœ‰é’©å­
        for handle in self.gradient_hooks.values():
            handle.remove()
        self.gradient_hooks = {}
        self.gradient_records = {}
        
        # æŸ¥æ‰¾æ‰€æœ‰å…¨è¿æ¥å±‚
        fc_count = 0
        for name, module in self.model.named_modules():
            if isinstance(module, nn.Linear):
                fc_count += 1
                # ä¸ºæƒé‡å‚æ•°æ³¨å†Œæ¢¯åº¦é’©å­
                hook = self._gradient_hook(name)
                handle = module.weight.register_hook(hook)
                self.gradient_hooks[name] = handle
                print(f"  - æ³¨å†Œé’©å­: {name} (è¾“å…¥={module.in_features}, è¾“å‡º={module.out_features})")
        
        print(f"æ€»å…±æ³¨å†Œäº† {fc_count} ä¸ªå…¨è¿æ¥å±‚çš„æ¢¯åº¦é’©å­")
        
    def _gradient_hook(self, name):
        """åˆ›å»ºæ¢¯åº¦é’©å­å‡½æ•°"""
        def hook(grad):
            # ç¡®ä¿æ¢¯åº¦æœ‰æ•ˆ
            if grad is None:
                return
            
            # è®¡ç®—æ¯ä¸ªè¾“å‡ºç¥ç»å…ƒçš„å¹³å‡æ¢¯åº¦
            if grad.dim() > 1:
                # å…¨è¿æ¥å±‚: å¯¹è¾“å…¥ç»´åº¦æ±‚å¹³å‡
                neuron_grads = grad.abs().mean(dim=1)  # [out_features]
            else:
                # 1Dæƒ…å†µ
                neuron_grads = grad.abs()
            
            # ä¿å­˜æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
            self.gradient_records[name] = neuron_grads.detach().cpu()
        return hook
    
    def analyze_gradients(self, dataloader, criterion, num_batches=5):
        """
        åˆ†æå…¨è¿æ¥å±‚æ¢¯åº¦åˆ†å¸ƒï¼ˆå‚è€ƒgradient_cray.pyï¼‰
        
        å‚æ•°:
        dataloader - æ•°æ®åŠ è½½å™¨
        criterion - æŸå¤±å‡½æ•°
        num_batches - åˆ†ææ‰¹æ¬¡æ•°
        
        è¿”å›:
        gradient_stats - æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯
        """
        print(f"\nå¼€å§‹åˆ†æ {num_batches} ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦åˆ†å¸ƒ...")
        
        # æ³¨å†Œæ¢¯åº¦é’©å­
        self.register_gradient_hooks()
        
        # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        self.model.train()
        
        # æ¢¯åº¦ç»Ÿè®¡æ”¶é›†å™¨
        gradient_stats = {}
        for name in self.gradient_hooks.keys():
            gradient_stats[name] = {'values': []}
        
        # å¤„ç†æŒ‡å®šæ‰¹æ¬¡æ•°æ®
        batch_count = 0
        data_iter = iter(dataloader)
        
        for batch_idx in range(num_batches):
            try:
                inputs, targets = next(data_iter)
                inputs, targets = inputs.to(next(self.model.parameters()).device), targets.to(next(self.model.parameters()).device)
            except StopIteration:
                print(f"æ•°æ®ä¸è¶³ï¼Œåªå¤„ç†äº† {batch_idx} ä¸ªæ‰¹æ¬¡")
                break
                
            # æ¸…ç©ºæ¢¯åº¦
            self.model.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(inputs)
            
            # å¤„ç†SNNè¾“å‡º
            if len(outputs.shape) > 2:
                outputs = outputs.mean(0)  # å¯¹æ—¶é—´ç»´åº¦æ±‚å¹³å‡
            
            # è®¡ç®—æŸå¤±
            loss = criterion(outputs, targets)
            
            # åå‘ä¼ æ’­ï¼ˆè§¦å‘æ¢¯åº¦é’©å­ï¼‰
            loss.backward()
            
            # æ”¶é›†æ¢¯åº¦æ•°æ®
            for name, grads in self.gradient_records.items():
                if grads is not None:
                    gradient_stats[name]['values'].extend(grads.numpy())
            
            batch_count += 1
            print(f"  å¤„ç†æ‰¹æ¬¡ {batch_count}/{num_batches}, æŸå¤±: {loss.item():.6f}")
        
        # è®¡ç®—æ¢¯åº¦ç»Ÿè®¡
        print("\nè®¡ç®—æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯...")
        for name, stats in gradient_stats.items():
            if stats['values']:
                values = np.array(stats['values'])
                stats['mean'] = np.mean(values)
                stats['std'] = np.std(values)
                stats['min'] = np.min(values)
                stats['max'] = np.max(values)
                stats['median'] = np.median(values)
                stats['num_neurons'] = len(values)
                
                # è®¡ç®—ç™¾åˆ†ä½æ•°
                stats['p25'] = np.percentile(values, 25)
                stats['p75'] = np.percentile(values, 75)
                stats['p95'] = np.percentile(values, 95)
        
        return gradient_stats
    
    def get_low_gradient_neurons(self, gradient_stats, ratio=0.1):
        """
        è¯†åˆ«ä½æ¢¯åº¦ç¥ç»å…ƒ
        
        å‚æ•°:
        gradient_stats - analyze_gradientsè¿”å›çš„ç»Ÿè®¡æ•°æ®
        ratio - è¦è¯†åˆ«çš„ç¥ç»å…ƒæ¯”ä¾‹
        
        è¿”å›:
        low_gradient_neurons - ä½æ¢¯åº¦ç¥ç»å…ƒåˆ—è¡¨
        """
        low_neurons = []
        
        # å¤„ç†æ¯å±‚çš„æ¢¯åº¦ç»Ÿè®¡
        for layer_name, stats in gradient_stats.items():
            if 'values' not in stats or not stats['values']:
                continue
                
            # å¯¹æ¢¯åº¦å€¼æ’åº
            grads = np.array(stats['values'])
            sorted_indices = np.argsort(grads)
            
            # è®¡ç®—ä½æ¢¯åº¦é˜ˆå€¼
            num_low = int(len(grads) * ratio)
            
            # æ”¶é›†ä½æ¢¯åº¦ç¥ç»å…ƒ
            for idx in sorted_indices[:num_low]:
                low_neurons.append({
                    'layer': layer_name,
                    'neuron_index': idx,
                    'grad_value': grads[idx],
                    'grad_percentile': (np.searchsorted(np.sort(grads), grads[idx]) + 1) / len(grads)
                })
        
        return low_neurons
    
    def print_gradient_analysis(self, gradient_stats):
        """æ‰“å°æ¢¯åº¦åˆ†æç»“æœ"""
        print("="*80)
        print("å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†å¸ƒåˆ†æ")
        print("="*80)
        
        if not gradient_stats:
            print("æ²¡æœ‰æ”¶é›†åˆ°æ¢¯åº¦æ•°æ®")
            return
        
        for layer_name, stats in gradient_stats.items():
            if not stats.get('values'):
                continue
                
            print(f"\nå±‚: {layer_name}")
            print(f"  ç¥ç»å…ƒæ•°é‡: {stats['num_neurons']:,}")
            print(f"  æ¢¯åº¦ç»Ÿè®¡:")
            print(f"    å‡å€¼: {stats['mean']:.8f}")
            print(f"    æ ‡å‡†å·®: {stats['std']:.8f}")
            print(f"    æœ€å°å€¼: {stats['min']:.8f}")
            print(f"    æœ€å¤§å€¼: {stats['max']:.8f}")
            print(f"    ä¸­ä½æ•°: {stats['median']:.8f}")
            print(f"  æ¢¯åº¦åˆ†å¸ƒ:")
            print(f"    25%åˆ†ä½æ•°: {stats['p25']:.8f}")
            print(f"    75%åˆ†ä½æ•°: {stats['p75']:.8f}")
            print(f"    95%åˆ†ä½æ•°: {stats['p95']:.8f}")
            print("-"*60)
        
        # åˆ†æä½æ¢¯åº¦ç¥ç»å…ƒ
        print("\nä½æ¢¯åº¦ç¥ç»å…ƒåˆ†æ:")
        for ratio in [0.05, 0.1, 0.2]:
            low_neurons = self.get_low_gradient_neurons(gradient_stats, ratio)
            print(f"  æ¢¯åº¦æœ€ä½ {ratio*100:.1f}% çš„ç¥ç»å…ƒæ•°é‡: {len(low_neurons)}")
            
            if low_neurons:
                # æŒ‰å±‚åˆ†ç»„ç»Ÿè®¡
                layer_counts = {}
                for neuron in low_neurons:
                    layer = neuron['layer']
                    if layer not in layer_counts:
                        layer_counts[layer] = 0
                    layer_counts[layer] += 1
                
                for layer, count in layer_counts.items():
                    print(f"    {layer}: {count} ä¸ª")
        
        print("="*80)
    
    def cleanup_hooks(self):
        """æ¸…ç†æ¢¯åº¦é’©å­"""
        for handle in self.gradient_hooks.values():
            handle.remove()
        self.gradient_hooks = {}
        self.gradient_records = {}

class OutputRedirector:
    """è¾“å‡ºé‡å®šå‘å™¨ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
        self.log.flush()
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è·å–VGG16å‚æ•°å’Œæ¢¯åº¦')
    parser.add_argument('--batch_size', default=32, type=int, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--device', default='0', type=str, help='è®¾å¤‡')
    parser.add_argument('--seed', default=42, type=int, help='éšæœºç§å­')
    parser.add_argument('--mode', choices=['ann', 'snn'], default='snn', help='æ¨¡å¼')
    parser.add_argument('--num_batches', default=5, type=int, help='æ¢¯åº¦åˆ†æçš„æ‰¹æ¬¡æ•°')

    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºé‡å®šå‘ï¼ˆé»˜è®¤ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"gradient_analysis_{args.mode}_{timestamp}.txt"
    output_redirector = OutputRedirector(filename)
    sys.stdout = output_redirector
    print(f"è¾“å‡ºå°†ä¿å­˜åˆ°æ–‡ä»¶: {filename}")
    
    # è®¾ç½®ç¯å¢ƒ
    os.environ["CUDA_VISIBLE_DEVICES"] = args.device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    seed_all(args.seed)
    
    print(f"è®¾å¤‡: {device}, éšæœºç§å­: {args.seed}")
    print(f"åˆ†ææ¨¡å¼: {args.mode}")
    print(f"æ¢¯åº¦åˆ†ææ‰¹æ¬¡æ•°: {args.num_batches}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºVGG16æ¨¡å‹...")
        model = modelpool('vgg16', 'cifar10')
        
        # ç›´æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = '/root/autodl-tmp/0-ANN2SNN-Allinone/2-ANN_SNN_QCFS-SRP/cifar10-checkpoints/vgg16_wd[0.0005].pth'
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # å¤„ç†æ—§ç‰ˆæœ¬state_dictçš„å…¼å®¹æ€§
        keys = list(state_dict.keys())
        for k in keys:
            if "relu.up" in k:
                state_dict[k[:-7]+'act.thresh'] = state_dict.pop(k)
            elif "up" in k:
                state_dict[k[:-2]+'thresh'] = state_dict.pop(k)
        
        model.load_state_dict(state_dict)
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        if args.mode == 'snn':
            model.set_T(8)
            model.set_L(4)
            print("è®¾ç½®ä¸ºSNNæ¨¡å¼")
        else:
            model.set_T(0)
            print("è®¾ç½®ä¸ºANNæ¨¡å¼")
        
        model.to(device)
        model.train()
        
        # # åŠ è½½æ•°æ®
        # print("åŠ è½½CIFAR10æ•°æ®é›†...")
        train_loader, test_loader = datapool('cifar10', args.batch_size)
        
        # # è·å–ä¸€æ‰¹æ•°æ®
        data_iter = iter(train_loader)
        images, labels = next(data_iter)
        images, labels = images.to(device), labels.to(device)
        
        # print(f"è¾“å…¥å½¢çŠ¶: {images.shape}, æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
        
        # # å‰å‘ä¼ æ’­
        # print("æ‰§è¡Œå‰å‘ä¼ æ’­...")
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01)
        
        optimizer.zero_grad()
        outputs = model(images)
        
        # # å¤„ç†SNNè¾“å‡º
        if len(outputs.shape) > 2:
            outputs = outputs.mean(0)
        
        loss = criterion(outputs, labels)
        print(f"æŸå¤±: {loss.item():.6f}")
        
        # # åå‘ä¼ æ’­
        # print("æ‰§è¡Œåå‘ä¼ æ’­...")
        loss.backward()
        
        # # åªæ‰“å°IFå±‚ä¿¡æ¯
        # print_if_module_info(model)
        
        # # æ‰“å°IFå±‚è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«è¾“å…¥è¾“å‡ºæ¢¯åº¦ï¼‰
        # print("\n" + "="*80)
        # print("IFå±‚è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«è¾“å…¥è¾“å‡ºæ¢¯åº¦ï¼‰")
        # print("="*80)
        # new_print_if_module_info(model)
        
        # è·å–IFå±‚çš„è¾“å…¥è¾“å‡ºæ¢¯åº¦ï¼ˆéœ€è¦å®Œæ•´çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼‰
        print("\n" + "="*80)
        print("IFå±‚è¾“å…¥è¾“å‡ºæ¢¯åº¦å®Œæ•´åˆ†æ")
        print("="*80)
        get_if_layer_input_output_gradients(model, train_loader, criterion)
        
        # # ä¸“é—¨åˆ†æIFå±‚çš„æ¢¯åº¦åˆ†å¸ƒç‰¹å¾
        # print("\n" + "="*80)
        # print("IFå±‚æ¢¯åº¦åˆ†å¸ƒç‰¹å¾è¯¦ç»†åˆ†æ")
        # print("="*80)
        # analyze_if_gradient_distribution(model, train_loader, criterion)
        
        return
        # åˆ†æå…¨è¿æ¥å±‚æ¢¯åº¦ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        print("\n" + "="*80)
        print("å¼€å§‹å…¨è¿æ¥å±‚æ¢¯åº¦åˆ†æ")
        print("="*80)
        
        # åˆ›å»ºæ¢¯åº¦åˆ†æå™¨
        analyzer = GradientAnalyzer(model)
        
        try:
            # åˆ†ææ¢¯åº¦åˆ†å¸ƒ
            gradient_stats = analyzer.analyze_gradients(
                train_loader, 
                criterion, 
                num_batches=args.num_batches
            )
            
            # æ‰“å°åˆ†æç»“æœ
            analyzer.print_gradient_analysis(gradient_stats)
            
            # ä¿å­˜å„å±‚æ¢¯åº¦ä¿¡æ¯åˆ°CSVæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            for layer_name, stats in gradient_stats.items():
                if not stats.get('values'):
                    continue
                
                # è·å–è¯¥å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼ˆæ€»æ¢¯åº¦æ•°é™¤ä»¥batchæ•°ï¼‰
                num_neurons = len(stats['values']) // args.num_batches
                
                # é‡å¡‘æ•°æ®ä¸º [num_neurons, num_batches] çš„å½¢çŠ¶
                gradient_values = np.array(stats['values']).reshape(num_neurons, args.num_batches)
                
                # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„å¹³å‡æ¢¯åº¦å€¼
                mean_gradients = np.mean(gradient_values, axis=1)
                
                # åˆ›å»ºDataFrame
                df = pd.DataFrame({
                    'neuron_index': range(num_neurons)
                })
                
                # æ·»åŠ æ¯ä¸ªbatchçš„æ¢¯åº¦å€¼åˆ—
                for i in range(args.num_batches):
                    df[f'gradient_batch_{i+1}'] = gradient_values[:, i]
                
                # æ·»åŠ å¹³å‡æ¢¯åº¦å€¼åˆ—
                df['gradient_mean'] = mean_gradients
                
                # ç”Ÿæˆæ–‡ä»¶å
                filename = f"gradient_analysis_{layer_name}_{timestamp}.csv"
                
                # ä¿å­˜åˆ°CSV
                df.to_csv(filename, index=False)
                print(f"å·²ä¿å­˜{layer_name}å±‚çš„æ¢¯åº¦ä¿¡æ¯åˆ°: {filename}")
                print(f"  ç¥ç»å…ƒæ•°é‡: {num_neurons}")
                print(f"  æ¯ä¸ªç¥ç»å…ƒåŒ…å«{args.num_batches}ä¸ªbatchçš„æ¢¯åº¦å€¼å’Œå¹³å‡å€¼")
            
            # è¯¦ç»†åˆ†æä½æ¢¯åº¦ç¥ç»å…ƒ
            print("\n" + "="*80)
            print("ä½æ¢¯åº¦ç¥ç»å…ƒè¯¦ç»†åˆ†æ")
            print("="*80)
            
            for ratio in [0.05, 0.1, 0.15, 0.2]:
                low_neurons = analyzer.get_low_gradient_neurons(gradient_stats, ratio)
                print(f"\næ¢¯åº¦æœ€ä½ {ratio*100:.1f}% çš„ç¥ç»å…ƒè¯¦æƒ…:")
                
                if low_neurons:
                    # æŒ‰å±‚åˆ†ç»„æ˜¾ç¤º
                    layer_groups = {}
                    for neuron in low_neurons:
                        layer = neuron['layer']
                        if layer not in layer_groups:
                            layer_groups[layer] = []
                        layer_groups[layer].append(neuron)
                    
                    for layer, neurons in layer_groups.items():
                        print(f"  {layer}: {len(neurons)} ä¸ªç¥ç»å…ƒ")
                        # æ˜¾ç¤ºå‰5ä¸ªæœ€ä½æ¢¯åº¦çš„ç¥ç»å…ƒ
                        for i, neuron in enumerate(sorted(neurons, key=lambda x: x['grad_value'])[:5]):
                            print(f"    #{i+1}: ç¥ç»å…ƒ{neuron['neuron_index']}, æ¢¯åº¦={neuron['grad_value']:.8f}, ç™¾åˆ†ä½={neuron['grad_percentile']:.3f}")
                else:
                    print("  æ— æ•°æ®")
            
        finally:
            # æ¸…ç†æ¢¯åº¦é’©å­
            analyzer.cleanup_hooks()
        
        print("\nâœ… å®Œæˆ!")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("python 0612get_grad.py --mode snn  # SNNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯å’Œæ¢¯åº¦åˆ†æ")
        print("python 0612get_grad.py --mode ann  # ANNæ¨¡å¼æŸ¥çœ‹IFå±‚ä¿¡æ¯å’Œæ¢¯åº¦åˆ†æ")
        print("python 0612get_grad.py --mode snn --num_batches 10  # æŒ‡å®šåˆ†ææ‰¹æ¬¡æ•°")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # æ¢å¤æ ‡å‡†è¾“å‡ºå¹¶å…³é—­æ–‡ä»¶
        if output_redirector is not None:
            sys.stdout = output_redirector.terminal
            output_redirector.close()
            print(f"è¾“å‡ºå·²ä¿å­˜åˆ°: {filename}")

if __name__ == "__main__":
    main() 

def test_new_print_if_module_info():
    """æµ‹è¯•new_print_if_module_infoå‡½æ•°çš„åŠŸèƒ½"""
    print("="*80)
    print("æµ‹è¯•new_print_if_module_infoå‡½æ•°")
    print("="*80)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = modelpool('vgg16', 'cifar10')
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = '/root/autodl-tmp/0-ANN2SNN-Allinone/2-ANN_SNN_QCFS-SRP/cifar10-checkpoints/vgg16_wd[0.0005].pth'
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # å¤„ç†æ—§ç‰ˆæœ¬state_dictçš„å…¼å®¹æ€§
        keys = list(state_dict.keys())
        for k in keys:
            if "relu.up" in k:
                state_dict[k[:-7]+'act.thresh'] = state_dict.pop(k)
            elif "up" in k:
                state_dict[k[:-2]+'thresh'] = state_dict.pop(k)
        
        model.load_state_dict(state_dict)
        
        # è®¾ç½®ä¸ºSNNæ¨¡å¼
        model.set_T(8)
        model.set_L(4)
        model.train()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_input = torch.randn(1, 3, 32, 32, requires_grad=True)
        criterion = nn.CrossEntropyLoss()
        
        # å‰å‘ä¼ æ’­
        output = model(test_input)
        if len(output.shape) > 2:
            output = output.mean(0)
        
        # è®¡ç®—æŸå¤±
        target = torch.tensor([0])
        loss = criterion(output, target)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æµ‹è¯•æ–°å‡½æ•°
        new_print_if_module_info(model)
        
        print("âœ… æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# å¦‚æœè¦è¿è¡Œæµ‹è¯•ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
# test_new_print_if_module_info() 

def analyze_if_gradient_distribution(model, dataloader, criterion):
    """ä¸“é—¨åˆ†æIFå±‚çš„æ¢¯åº¦åˆ†å¸ƒç‰¹å¾"""
    print("="*80)
    print("IFå±‚æ¢¯åº¦åˆ†å¸ƒç‰¹å¾åˆ†æ")
    print("="*80)
    
    from Models.layer import IF
    
    # å­˜å‚¨æ¢¯åº¦ä¿¡æ¯çš„å­—å…¸
    gradient_info = {}
    
    # ä¸ºæ¯ä¸ªIFå±‚æ³¨å†Œé’©å­
    def register_gradient_hooks():
        hooks = []
        
        for name, module in model.named_modules():
            if isinstance(module, IF):
                gradient_info[name] = {
                    'input_grad': None,
                    'output_grad': None,
                    'threshold_grad': None,
                    'module': module
                }
                
                # æ³¨å†Œè¾“å‡ºæ¢¯åº¦é’©å­
                def create_output_hook(module_name):
                    def output_hook(module, grad_input, grad_output):
                        if grad_output[0] is not None:
                            gradient_info[module_name]['output_grad'] = grad_output[0].detach().clone()
                        
                        # æ•è·è¾“å…¥æ¢¯åº¦ï¼ˆå¯¹äºIFå±‚ï¼Œåªæœ‰dL/dxï¼‰
                        if grad_input[0] is not None:
                            gradient_info[module_name]['input_grad'] = grad_input[0].detach().clone()
                        
                        # æ•è·é˜ˆå€¼æ¢¯åº¦
                        if module.thresh.grad is not None:
                            gradient_info[module_name]['threshold_grad'] = module.thresh.grad.detach().clone()
                        
                    return output_hook
                
                hook = module.register_full_backward_hook(create_output_hook(name))
                hooks.append(hook)
        
        return hooks
    
    # æ³¨å†Œé’©å­
    hooks = register_gradient_hooks()
    
    try:
        # ç¡®ä¿æ¨¡å‹å¤„äºè®­ç»ƒæ¨¡å¼
        model.train()
        
        # è·å–ä¸€æ‰¹æ•°æ®
        data_iter = iter(dataloader)
        inputs, targets = next(data_iter)
        inputs, targets = inputs.to(next(model.parameters()).device), targets.to(next(model.parameters()).device)
        
        # æ¸…ç©ºæ¢¯åº¦
        model.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(inputs)
        
        # å¤„ç†SNNè¾“å‡º
        if len(outputs.shape) > 2:
            outputs = outputs.mean(0)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, targets)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # åˆ†ææ¯ä¸ªIFå±‚çš„æ¢¯åº¦åˆ†å¸ƒ
        for name, module in model.named_modules():
            if isinstance(module, IF):
                print(f"\nğŸ” IFå±‚: {name}")
                print("-" * 50)
                
                # 1. é˜ˆå€¼æ¢¯åº¦åˆ†æ
                thresh_grad = gradient_info[name]['threshold_grad']
                if thresh_grad is not None:
                    print(f"ğŸ¯ é˜ˆå€¼æ¢¯åº¦ (dL/dthresh):")
                    print(f"  æ•°å€¼: {thresh_grad.item():.8f}")
                    print(f"  ç»å¯¹å€¼: {abs(thresh_grad.item()):.8f}")
                    print(f"  ç¬¦å·: {'æ­£' if thresh_grad.item() > 0 else 'è´Ÿ' if thresh_grad.item() < 0 else 'é›¶'}")
                else:
                    print(f"ğŸ¯ é˜ˆå€¼æ¢¯åº¦: None")
                
                # 2. è¾“å…¥æ¢¯åº¦åˆ†æ
                input_grad = gradient_info[name]['input_grad']
                if input_grad is not None:
                    print(f"\nğŸ“¥ è¾“å…¥æ¢¯åº¦ (dL/dx) åˆ†å¸ƒ:")
                    print(f"  å½¢çŠ¶: {list(input_grad.shape)}")
                    print(f"  èŒƒæ•°: {input_grad.norm().item():.6f}")
                    print(f"  å‡å€¼: {input_grad.mean().item():.6f}")
                    print(f"  æ ‡å‡†å·®: {input_grad.std().item():.6f}")
                    print(f"  æœ€å°å€¼: {input_grad.min().item():.6f}")
                    print(f"  æœ€å¤§å€¼: {input_grad.max().item():.6f}")
                    
                    # æ¢¯åº¦åˆ†å¸ƒç»Ÿè®¡
                    grad_abs = input_grad.abs()
                    print(f"  ç»å¯¹å€¼åˆ†å¸ƒ:")
                    print(f"    25%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.25).item():.6f}")
                    print(f"    50%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.50).item():.6f}")
                    print(f"    75%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.75).item():.6f}")
                    print(f"    90%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.90).item():.6f}")
                    print(f"    95%åˆ†ä½æ•°: {torch.quantile(grad_abs, 0.95).item():.6f}")
                    
                    # éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (input_grad != 0).float().mean().item()
                    print(f"  éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                    
                    # æ¢¯åº¦ç¨€ç–æ€§åˆ†æ
                    small_grad_ratio = (grad_abs < 0.01).float().mean().item()
                    print(f"  å°æ¢¯åº¦æ¯”ä¾‹ (<0.01): {small_grad_ratio:.2%}")
                    
                    # æ¢¯åº¦æ–¹å‘åˆ†æ
                    positive_ratio = (input_grad > 0).float().mean().item()
                    negative_ratio = (input_grad < 0).float().mean().item()
                    zero_ratio = (input_grad == 0).float().mean().item()
                    print(f"  æ¢¯åº¦æ–¹å‘åˆ†å¸ƒ:")
                    print(f"    æ­£å€¼: {positive_ratio:.2%}")
                    print(f"    è´Ÿå€¼: {negative_ratio:.2%}")
                    print(f"    é›¶å€¼: {zero_ratio:.2%}")
                else:
                    print(f"ğŸ“¥ è¾“å…¥æ¢¯åº¦: None")
                
                # 3. è¾“å‡ºæ¢¯åº¦åˆ†æ
                output_grad = gradient_info[name]['output_grad']
                if output_grad is not None:
                    print(f"\nğŸ“¤ è¾“å‡ºæ¢¯åº¦ (dL/dy) åˆ†å¸ƒ:")
                    print(f"  å½¢çŠ¶: {list(output_grad.shape)}")
                    print(f"  èŒƒæ•°: {output_grad.norm().item():.6f}")
                    print(f"  å‡å€¼: {output_grad.mean().item():.6f}")
                    print(f"  æ ‡å‡†å·®: {output_grad.std().item():.6f}")
                    print(f"  æœ€å°å€¼: {output_grad.min().item():.6f}")
                    print(f"  æœ€å¤§å€¼: {output_grad.max().item():.6f}")
                    
                    # è¾“å‡ºæ¢¯åº¦åˆ†å¸ƒç»Ÿè®¡
                    out_grad_abs = output_grad.abs()
                    print(f"  ç»å¯¹å€¼åˆ†å¸ƒ:")
                    print(f"    25%åˆ†ä½æ•°: {torch.quantile(out_grad_abs, 0.25).item():.6f}")
                    print(f"    50%åˆ†ä½æ•°: {torch.quantile(out_grad_abs, 0.50).item():.6f}")
                    print(f"    75%åˆ†ä½æ•°: {torch.quantile(out_grad_abs, 0.75).item():.6f}")
                    print(f"    90%åˆ†ä½æ•°: {torch.quantile(out_grad_abs, 0.90).item():.6f}")
                    print(f"    95%åˆ†ä½æ•°: {torch.quantile(out_grad_abs, 0.95).item():.6f}")
                    
                    # éé›¶æ¢¯åº¦æ¯”ä¾‹
                    non_zero_ratio = (output_grad != 0).float().mean().item()
                    print(f"  éé›¶æ¢¯åº¦æ¯”ä¾‹: {non_zero_ratio:.2%}")
                else:
                    print(f"ğŸ“¤ è¾“å‡ºæ¢¯åº¦: None")
                
                # 4. æ¢¯åº¦ä¼ æ’­æ•ˆç‡åˆ†æ
                if input_grad is not None and output_grad is not None:
                    input_norm = input_grad.norm().item()
                    output_norm = output_grad.norm().item()
                    if output_norm > 0:
                        propagation_ratio = input_norm / output_norm
                        print(f"\nğŸ”„ æ¢¯åº¦ä¼ æ’­æ•ˆç‡:")
                        print(f"  è¾“å…¥æ¢¯åº¦èŒƒæ•°: {input_norm:.6f}")
                        print(f"  è¾“å‡ºæ¢¯åº¦èŒƒæ•°: {output_norm:.6f}")
                        print(f"  ä¼ æ’­æ¯”ä¾‹: {propagation_ratio:.6f}")
                        
                        if propagation_ratio < 0.1:
                            print(f"  âš ï¸  è­¦å‘Š: æ¢¯åº¦ä¼ æ’­æ¯”ä¾‹è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±")
                        elif propagation_ratio > 10:
                            print(f"  âš ï¸  è­¦å‘Š: æ¢¯åº¦ä¼ æ’­æ¯”ä¾‹è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸")
                        else:
                            print(f"  âœ… æ¢¯åº¦ä¼ æ’­æ¯”ä¾‹æ­£å¸¸")
                
                print("-" * 50)
        
        print(f"\nğŸ“Š æ€»ç»“:")
        print(f"  åˆ†æäº† {len([m for m in model.modules() if isinstance(m, IF)])} ä¸ªIFå±‚")
        print(f"  æ¯ä¸ªIFå±‚åªæœ‰1ä¸ªé˜ˆå€¼å‚æ•°ï¼Œæ— æƒé‡å’Œåç½®å‚æ•°")
        print(f"  æ¢¯åº¦ä¿¡æ¯åŒ…æ‹¬: è¾“å…¥æ¢¯åº¦(dL/dx)ã€è¾“å‡ºæ¢¯åº¦(dL/dy)ã€é˜ˆå€¼æ¢¯åº¦(dL/dthresh)")
    
    finally:
        # æ¸…ç†é’©å­
        for hook in hooks:
            hook.remove()
    
    print("="*80) 

def test_analyze_if_gradient_distribution():
    """æµ‹è¯•IFå±‚æ¢¯åº¦åˆ†å¸ƒåˆ†æå‡½æ•°"""
    print("="*80)
    print("æµ‹è¯•IFå±‚æ¢¯åº¦åˆ†å¸ƒåˆ†æå‡½æ•°")
    print("="*80)
    
    import torch
    import torch.nn as nn
    from Models import modelpool
    from Preprocess import datapool
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºVGG16æ¨¡å‹...")
        model = modelpool('vgg16', 'cifar10')
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = '/root/autodl-tmp/0-ANN2SNN-Allinone/2-ANN_SNN_QCFS-SRP/cifar10-checkpoints/vgg16_wd[0.0005].pth'
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
        # å¤„ç†æ—§ç‰ˆæœ¬state_dictçš„å…¼å®¹æ€§
        keys = list(state_dict.keys())
        for k in keys:
            if "relu.up" in k:
                state_dict[k[:-7]+'act.thresh'] = state_dict.pop(k)
            elif "up" in k:
                state_dict[k[:-2]+'thresh'] = state_dict.pop(k)
        
        model.load_state_dict(state_dict)
        print("âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # è®¾ç½®ä¸ºSNNæ¨¡å¼
        model.set_T(8)
        model.set_L(4)
        print("è®¾ç½®ä¸ºSNNæ¨¡å¼: T=8, L=4")
        
        model.to(device)
        model.train()
        
        # åŠ è½½æ•°æ®
        print("åŠ è½½CIFAR10æ•°æ®é›†...")
        train_loader, _ = datapool('cifar10', 32)
        
        # å®šä¹‰æŸå¤±å‡½æ•°
        criterion = nn.CrossEntropyLoss()
        
        # è¿è¡Œæ¢¯åº¦åˆ†å¸ƒåˆ†æ
        print("å¼€å§‹IFå±‚æ¢¯åº¦åˆ†å¸ƒåˆ†æ...")
        analyze_if_gradient_distribution(model, train_loader, criterion)
        
        print("âœ… æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# å¦‚æœè¦è¿è¡Œæµ‹è¯•ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
# test_analyze_if_gradient_distribution() 