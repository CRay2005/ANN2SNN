#!/usr/bin/env python3
"""
è¯Šæ–­Hessianæƒé‡é‡è¦æ€§ä¸º0çš„æ ¹æœ¬åŸå› 
"""

import torch
import torch.nn as nn
from Models import modelpool
from Preprocess import datapool
from Models.layer import IF


def diagnose_if_layer_issue():
    """è¯Šæ–­IFå±‚çš„é—®é¢˜"""
    print("="*80)
    print("ğŸ” è¯Šæ–­IFå±‚Hessiané‡è¦æ€§ä¸º0çš„é—®é¢˜")
    print("="*80)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åˆ›å»ºæ¨¡å‹
    model = modelpool('vgg16', 'cifar10')
    model.set_L(8)
    model.set_T(0)  # ANNæ¨¡å¼
    model.to(device)
    
    # åŠ è½½æ•°æ®
    train_loader, _ = datapool('cifar10', 16)
    
    # è·å–ä¸€ä¸ªbatch
    for batch_idx, (data, target) in enumerate(train_loader):
        if batch_idx > 0:
            break
        
        data, target = data.to(device), target.to(device)
        
        # 1. æ£€æŸ¥IFå±‚å‚æ•°åˆå§‹åŒ–çŠ¶æ€
        print("1. æ£€æŸ¥IFå±‚å‚æ•°åˆå§‹åŒ–çŠ¶æ€:")
        print("-" * 40)
        
        if_params = []
        for name, module in model.named_modules():
            if isinstance(module, IF):
                for param_name, param in module.named_parameters():
                    full_name = f"{name}.{param_name}"
                    if_params.append((full_name, param))
                    print(f"IFå±‚ {full_name}:")
                    print(f"  å½¢çŠ¶: {param.shape}")
                    print(f"  å€¼: {param.data}")
                    print(f"  èŒƒæ•°: {param.norm():.6f}")
                    print(f"  requires_grad: {param.requires_grad}")
        
        # 2. æµ‹è¯•å‰å‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—
        print("\n2. æµ‹è¯•å‰å‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—:")
        print("-" * 40)
        
        model.zero_grad()
        output = model(data)
        loss = nn.CrossEntropyLoss()(output, target)
        loss.backward(create_graph=True)
        
        print(f"æŸå¤±å€¼: {loss.item():.6f}")
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æ£€æŸ¥IFå±‚æ¢¯åº¦
        print("\n3. æ£€æŸ¥IFå±‚æ¢¯åº¦:")
        print("-" * 40)
        
        for name, param in if_params:
            if param.grad is not None:
                print(f"IFå±‚ {name}:")
                print(f"  æ¢¯åº¦å€¼: {param.grad.data}")
                print(f"  æ¢¯åº¦èŒƒæ•°: {param.grad.norm():.6f}")
                print(f"  æ¢¯åº¦æ˜¯å¦ä¸º0: {torch.allclose(param.grad, torch.zeros_like(param.grad))}")
            else:
                print(f"IFå±‚ {name}: æ— æ¢¯åº¦ï¼")
        
        # 4. æµ‹è¯•ç®€å•çš„Hessianè®¡ç®—
        print("\n4. æµ‹è¯•ç®€å•çš„Hessianè®¡ç®—:")
        print("-" * 40)
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªIFå±‚è¿›è¡Œæµ‹è¯•
        if if_params:
            test_name, test_param = if_params[0]
            print(f"æµ‹è¯•IFå±‚: {test_name}")
            
            if test_param.grad is not None:
                # ç”Ÿæˆéšæœºå‘é‡
                v = torch.randn_like(test_param)
                print(f"éšæœºå‘é‡v: {v}")
                print(f"vçš„èŒƒæ•°: {v.norm():.6f}")
                
                try:
                    # è®¡ç®—Hessian-å‘é‡ä¹˜ç§¯
                    hv = torch.autograd.grad([test_param.grad], [test_param], 
                                           grad_outputs=[v], retain_graph=True)[0]
                    print(f"Hessian-å‘é‡ä¹˜ç§¯Hv: {hv}")
                    print(f"Hvçš„èŒƒæ•°: {hv.norm():.6f}")
                    
                    # è®¡ç®—trace
                    trace = torch.sum(v * hv).item()
                    print(f"traceä¼°è®¡ (v^T * H * v): {trace:.6f}")
                    
                    # è®¡ç®—é‡è¦æ€§
                    weight_norm_sq = test_param.norm(p=2) ** 2
                    importance = trace * weight_norm_sq.item()
                    print(f"æƒé‡èŒƒæ•°å¹³æ–¹: {weight_norm_sq:.6f}")
                    print(f"é‡è¦æ€§ (trace * weight_norm^2): {importance:.6f}")
                    
                except Exception as e:
                    print(f"è®¡ç®—Hessianå¤±è´¥: {e}")
            else:
                print("æ²¡æœ‰æ¢¯åº¦ï¼Œæ— æ³•è®¡ç®—Hessian")
        
        # 5. åˆ†æé—®é¢˜åŸå› 
        print("\n5. é—®é¢˜åˆ†æ:")
        print("-" * 40)
        
        # æ£€æŸ¥IFå±‚æ˜¯å¦å¤„äºæ¿€æ´»çŠ¶æ€
        if_layers = []
        for name, module in model.named_modules():
            if isinstance(module, IF):
                if_layers.append((name, module))
        
        print(f"å‘ç° {len(if_layers)} ä¸ªIFå±‚")
        
        # æµ‹è¯•IFå±‚åœ¨ANNæ¨¡å¼ä¸‹çš„è¡Œä¸º
        print("\næµ‹è¯•IFå±‚åœ¨ANNæ¨¡å¼ä¸‹çš„è¡Œä¸º:")
        test_input = torch.randn(4, 64, 32, 32).to(device)  # æ¨¡æ‹Ÿä¸­é—´å±‚è¾“å…¥
        
        for name, if_layer in if_layers[:3]:  # åªæµ‹è¯•å‰3ä¸ª
            print(f"\nIFå±‚ {name}:")
            print(f"  T (æ—¶é—´æ­¥): {if_layer.T}")
            print(f"  thresh: {if_layer.thresh}")
            
            try:
                # æµ‹è¯•IFå±‚çš„å‰å‘ä¼ æ’­
                if_layer.eval()
                with torch.no_grad():
                    test_output = if_layer(test_input)
                    print(f"  è¾“å…¥å½¢çŠ¶: {test_input.shape}")
                    print(f"  è¾“å‡ºå½¢çŠ¶: {test_output.shape}")
                    print(f"  è¾“å‡ºèŒƒå›´: [{test_output.min():.4f}, {test_output.max():.4f}]")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰éé›¶è¾“å‡º
                    nonzero_ratio = (test_output != 0).float().mean().item()
                    print(f"  éé›¶è¾“å‡ºæ¯”ä¾‹: {nonzero_ratio:.4f}")
                    
            except Exception as e:
                print(f"  æµ‹è¯•å¤±è´¥: {e}")
        
        break
    
    print("\n" + "="*80)
    print("ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print("="*80)
    print("1. ANNæ¨¡å¼ä¸‹IFå±‚å¯èƒ½é€€åŒ–ä¸ºidentityå‡½æ•°ï¼Œå¯¼è‡´æ¢¯åº¦ä¸º0")
    print("2. threshå‚æ•°å¯èƒ½éœ€è¦ç‰¹æ®Šåˆå§‹åŒ–")
    print("3. å¯èƒ½éœ€è¦åœ¨SNNæ¨¡å¼ä¸‹è®¡ç®—é‡è¦æ€§")
    print("4. å¯èƒ½éœ€è¦ä¿®æ”¹é‡è¦æ€§è®¡ç®—å…¬å¼")


if __name__ == "__main__":
    diagnose_if_layer_issue() 